{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configura√ß√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiza√ß√£o de configura√ß√µes do servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psutil\n",
    "import psutil\n",
    "import platform\n",
    "import shutil\n",
    "\n",
    "# Informa√ß√µes do sistema\n",
    "print(f\"Sistema operacional: {platform.system()} {platform.release()}\")\n",
    "print(f\"Arquitetura: {platform.machine()}\")\n",
    "print(f\"Processador: {platform.processor()}\")\n",
    "\n",
    "# Mem√≥ria\n",
    "mem = psutil.virtual_memory()\n",
    "print(f\"Mem√≥ria total: {mem.total / (1024**3):.2f} GB\")\n",
    "print(f\"Mem√≥ria dispon√≠vel: {mem.available / (1024**3):.2f} GB\")\n",
    "print(f\"Uso de mem√≥ria: {mem.percent}%\")\n",
    "\n",
    "# CPU\n",
    "print(f\"N√∫mero de CPUs f√≠sicas: {psutil.cpu_count(logical=False)}\")\n",
    "print(f\"N√∫mero de CPUs l√≥gicas: {psutil.cpu_count(logical=True)}\")\n",
    "print(f\"Uso da CPU: {psutil.cpu_percent(interval=1)}%\")\n",
    "\n",
    "# Disco\n",
    "total, used, free = shutil.disk_usage(\"/\")\n",
    "print(f\"Espa√ßo total em disco: {total / (1024**3):.2f} GB\")\n",
    "print(f\"Espa√ßo usado: {used / (1024**3):.2f} GB\")\n",
    "print(f\"Espa√ßo livre: {free / (1024**3):.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando vers√µes instaladas no sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, numpy as np, sys\n",
    "print(sys.executable)      \n",
    "print(\"Python\", sys.version)\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"NumPy:\", np.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instala√ß√£o das bibliotecas necess√°rias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala√ß√£o das bibliotecas necess√°rias (caso n√£o estejam instaladas)\n",
    "!pip install -q scikit-image\n",
    "!pip install -q keras-tuner\n",
    "%pip install -U pip setuptools wheel\n",
    "%pip install -U optuna\n",
    "%pip install -U optuna-integration[tfkeras]\n",
    "%pip install -U optuna optuna-dashboard\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa√ß√£o das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√£o das bibliotecas\n",
    "import os, zipfile, cv2, time, datetime\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.losses import mse\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.image import ssim_multiscale\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.stats import kruskal\n",
    "import keras_tuner as kt\n",
    "import optuna\n",
    "print(optuna.__version__)\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "import edgeimpulse as ei\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from typing import Dict, Any, Optional\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribui√ß√£o em m√∫ltiplas GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Detecta e inicializa a estrat√©gia para m√∫ltiplas GPUs\n",
    "try:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(f'Estrat√©gia de distribui√ß√£o: {strategy}')\n",
    "except ValueError:\n",
    "    strategy = tf.distribute.get_strategy() # Estrat√©gia padr√£o para uma √∫nica GPU ou CPU\n",
    "    print(f'N√£o foi poss√≠vel detectar m√∫ltiplas GPUs. Usando a estrat√©gia padr√£o: {strategy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©-processamento carregamento das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_imagens(pasta, tamanho=(128, 128), max_imgs=3000):\n",
    "    \"\"\"\n",
    "    Carrega e pr√©-processa imagens de um diret√≥rio.\n",
    "    \"\"\"\n",
    "    imagens = []\n",
    "    # Cria uma lista de caminhos para as imagens\n",
    "    caminhos_imagens = [os.path.join(pasta, img_nome) for img_nome in os.listdir(pasta)[:max_imgs]]\n",
    "\n",
    "    for img_path in tqdm(caminhos_imagens):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, tamanho)\n",
    "            img = img.astype('float32') / 255.0\n",
    "            imagens.append(img)\n",
    "    return np.array(imagens)\n",
    "\n",
    "# Caminhos para os datasets do ambiente Kaggle\n",
    "base_path = 'datasets/sard_dataset/search-and-rescue-2'\n",
    "\n",
    "# Carregando os dados\n",
    "print(\"Carregando o conjunto de treinamento...\")\n",
    "X_train = carregar_imagens(os.path.join(base_path, 'train/images'), max_imgs=5000)\n",
    "\n",
    "print(\"Carregando o conjunto de valida√ß√£o...\")\n",
    "X_val = carregar_imagens(os.path.join(base_path, 'valid/images'), max_imgs=1000)\n",
    "\n",
    "print(\"Carregando o conjunto de teste...\")\n",
    "X_test = carregar_imagens(os.path.join(base_path, 'test/images'), max_imgs=1000)\n",
    "\n",
    "print(\"\\nDados carregados com sucesso!\")\n",
    "print(f\"Formato do conjunto de treinamento: {X_train.shape}\")\n",
    "print(f\"Formato do conjunto de valida√ß√£o: {X_val.shape}\")\n",
    "print(f\"Formato do conjunto de teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defini√ß√£o dos Modelos de Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentativa com fun√ß√µes de perdas combinadas n√£o tiveram resultados finais satisfat√≥rios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun√ß√£o de perda combinada 1\n",
    "Usar apenas o mse (erro quadr√°tico m√©dio) √© bom para o PSNR, mas n√£o captura a percep√ß√£o visual. A melhoria √© combinar o mse com o SSIM, que mede a similaridade estrutural e √© mais alinhado com a percep√ß√£o humana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable(package=\"Custom\")\n",
    "def make_custom_loss(alpha=0.84):\n",
    "    \"\"\"Retorna uma fun√ß√£o de perda: alpha*SSIM_loss + (1-alpha)*MSE.\"\"\"\n",
    "    def loss(y_true, y_pred):\n",
    "        # Garante faixa [0,1] para o SSIM\n",
    "        y_pred_clip = tf.clip_by_value(y_pred, 0.0, 1.0)\n",
    "\n",
    "        # SSIM por amostra (1-SSIM vira erro). shape: (batch,)\n",
    "        ssim_loss = 1.0 - tf.image.ssim(y_true, y_pred_clip, max_val=1.0)\n",
    "\n",
    "        # MSE por amostra (mant√©m por-imagem e deixa o Keras reduzir)\n",
    "        mse_loss = tf.reduce_mean(tf.square(y_true - y_pred), axis=[1, 2, 3])\n",
    "\n",
    "        return alpha * ssim_loss + (1.0 - alpha) * mse_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun√ß√£o de perda combinada 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mse_ssim(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o de perda combinada: 80% MSE + 20% (1 - SSIM)\n",
    "    - Mant√©m PSNR elevado (MSE ainda domina)\n",
    "    - Incentiva preserva√ß√£o de estrutura (SSIM)\n",
    "    \"\"\"\n",
    "    # MSE\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    # SSIM Loss (1 - SSIM)\n",
    "    ssim_loss = 1.0 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    # Combina√ß√£o ponderada\n",
    "    return 0.8 * mse_loss + 0.2 * ssim_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AE Convencional Convolucional Inicial\n",
    "\n",
    "- üîß Hiperpar√¢metros\n",
    "- Input Image Shape: 128 x 128 x 3   \n",
    "- Encoder layers: 2 conv2d + 2 maxmpooling\n",
    "- Decoder layers: 2 conv2d + 2 upsampling\n",
    "- Activation function: relu + sigmoid\n",
    "- Optimizer: Adam\n",
    "- Loss function: MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convencional inicial\n",
    "def criar_autoencoder(input_shape=(128,128,3)):\n",
    "    inp = Input(shape=input_shape, name='conv_input')\n",
    "    #Encoder\n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inp)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "    x = layers.Conv2D(16, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "    x = layers.Conv2D(16, 3, activation='relu', padding='same')(x)\n",
    "    #Decoder\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = layers.Conv2D(16, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    out = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoenc = Model(inp, out, name='autoencoder_conv')\n",
    "    autoenc.compile(optimizer='adam', loss='mse')\n",
    "    return autoenc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AE Convencional Convolucional Melhorado\n",
    "\n",
    "- üîß Hiperpar√¢metros\n",
    "- Input Image Shape: 128 x 128 x 3   \n",
    "- Encoder layers: 2 conv2d + 2 batchnormalization +  2 maxmpooling\n",
    "- Decoder layers: 4 conv2dtranspose + + 2 batchnormalization +  1 conv2d\n",
    "- Activation function: relu + sigmoid\n",
    "- Optimizer: Adam\n",
    "- Loss function: MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convencional Melhorado\n",
    "def criar_autoencoder_melhorado(input_shape=(128,128,3)):\n",
    "    \"\"\"\n",
    "    Cria um autoencoder convolucional com arquitetura aprimorada.\n",
    "    - Mais camadas para maior capacidade de extra√ß√£o de features.\n",
    "    - Regulariza√ß√£o L2 para evitar overfitting.\n",
    "    - Batch Normalization para estabilidade e treinamento mais r√°pido.\n",
    "    \"\"\"\n",
    "    # Encoder\n",
    "    inp = Input(shape=input_shape, name='conv_input')\n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(1e-4))(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x) # Dimens√£o: 64x64\n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x) # Dimens√£o: 32x32\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Conv2DTranspose(32, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2DTranspose(32, 3, activation='relu', strides=(2, 2), padding='same')(x) # UpSample para 64x64\n",
    "    x = layers.Conv2DTranspose(64, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, activation='relu', strides=(2, 2), padding='same')(x) # UpSample para 128x128\n",
    "    out = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoenc = Model(inp, out, name='autoencoder_conv_melhorado')\n",
    "    autoenc.compile(optimizer='adam', loss='mse')\n",
    "    return autoenc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AE Variacional Inicial\n",
    "\n",
    "-üîß Hiperpar√¢metros\n",
    "- Input Image Shape: 128 x 128 x 3\n",
    "- Latent dim: 64 * s√≥ nesse porque?  \n",
    "- Encoder layers: 2 conv2d + 2 maxmpooling + 1 flaten\n",
    "- Decoder layers: Dense + Reshape+ Upsampling + Conv2d + Upsampling + Conv2d\n",
    "- Activation function: relu + sigmoid\n",
    "- Optimizer: Adam\n",
    "- Loss function: MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo inicial\n",
    "@tf.keras.utils.register_keras_serializable(package=\"CustomVAE\")\n",
    "def sampling_vae_func(args):\n",
    "    \"\"\"Fun√ß√£o de amostragem para VAEs baseados em Lambda layer (VAE Inicial).\"\"\"\n",
    "    mu, log_var = args\n",
    "    #  tf (mais robusto que K.random_normal no tf.keras)\n",
    "    eps = tf.random.normal(shape=tf.shape(mu))\n",
    "    return mu + tf.exp(0.5 * log_var) * eps    \n",
    "   \n",
    "def criar_vae(input_shape=(128,128,3), latent_dim=64):\n",
    "\n",
    "    # Encoder\n",
    "    inputs = Input(shape=input_shape, name='encoder_input')\n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "    x = layers.Conv2D(16, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "    flat = layers.Flatten()(x)\n",
    "\n",
    "    mu      = layers.Dense(latent_dim, name='mu')(flat)\n",
    "    log_var = layers.Dense(latent_dim, name='log_var')(flat)\n",
    "    z = layers.Lambda(sampling_vae_func, output_shape=(latent_dim,), name='z')([mu, log_var])\n",
    "\n",
    "    # Decoder\n",
    "    dec_in = Input(shape=(latent_dim,), name='decoder_input')\n",
    "    y = layers.Dense(32*32*16, activation='relu')(dec_in)\n",
    "    y = layers.Reshape((32,32,16))(y)\n",
    "    y = layers.UpSampling2D(2)(y)\n",
    "    y = layers.Conv2D(16, 3, activation='relu', padding='same')(y)\n",
    "    y = layers.UpSampling2D(2)(y)\n",
    "    decoded = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(y)\n",
    "\n",
    "    decoder = Model(dec_in, decoded, name='decoder')\n",
    "    outputs = decoder(z)\n",
    "    \n",
    "    vae = Model(inputs, outputs, name='vae')\n",
    "    vae.compile(optimizer='adam', loss=mse)\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AE Variacional Melhorado\n",
    "\n",
    "- üîß Hiperpar√¢metros\n",
    "- Input Image Shape: 128 x 128 x 3\n",
    "- Latent dim: 128 * aumentou \n",
    "- Encoder layers: 2x(conv2d + batchnormalization + maxpooling) + FLaten\n",
    "- Decoder layers: Dense + Reshape+  Conv2dtranspose + Conv2dtranspose + Conv2d\n",
    "- Activation function: relu + sigmoid\n",
    "- Optimizer: Adam\n",
    "- Loss function: MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Autoencoder Variacional (VAE)\n",
    "\n",
    "@register_keras_serializable()\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta  \n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'encoder': serialize(self.encoder),\n",
    "            'decoder': serialize(self.decoder),\n",
    "            'beta': self.beta,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        beta = config.pop('beta', 1.0)\n",
    "        encoder = tf.keras.utils.deserialize_keras_object(config.pop('encoder'))\n",
    "        decoder = tf.keras.utils.deserialize_keras_object(config.pop('decoder')) \n",
    "        return cls(encoder=encoder, decoder=decoder, **config)\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Entrada de dados\n",
    "            x, _ = data\n",
    "\n",
    "            # Executa o modelo\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "\n",
    "            # Calcula a perda de reconstru√ß√£o\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "               mse(x, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= 128 * 128\n",
    "\n",
    "            # Calcula a perda KL\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "\n",
    "            weighted_kl_loss = kl_loss * self.beta \n",
    "            \n",
    "            total_loss = reconstruction_loss + weighted_kl_loss \n",
    "\n",
    "        # Calcula gradientes e otimiza\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        # Atualiza m√©tricas\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Desempacota o data (X, y), onde y √© ignorado para autoencoders\n",
    "        x, _ = data \n",
    "\n",
    "        # 1. Executa o modelo (Forward Pass)\n",
    "        z_mean, z_log_var, z = self.encoder(x)\n",
    "        reconstruction = self.decoder(z)\n",
    "\n",
    "        # 2. Calcula a Perda de Reconstru√ß√£o\n",
    "        # Certifique-se de que 'mse' (Mean Squared Error) est√° acess√≠vel neste escopo\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            mse(x, reconstruction)\n",
    "        )\n",
    "        # Aplica o mesmo fator de escala usado no train_step\n",
    "        reconstruction_loss *= 128 * 128 \n",
    "\n",
    "        # 3. Calcula a Perda KL\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "\n",
    "        # 4. Calcula a Perda Total\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        # 5. Atualiza os rastreadores de m√©tricas\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        # 6. Retorna as m√©tricas (as mesmas do train_step)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(), # Corresponde a val_total_loss\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        return self.decoder(z)\n",
    "\n",
    "def criar_vae_melhorado(input_shape=(128,128,3), latent_dim=128, beta=0.1): # Aumenta a latent_dim\n",
    "    # Encoder\n",
    "    inputs = layers.Input(shape=input_shape, name='encoder_input')\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "\n",
    "    flatten = layers.Flatten()(x)\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(flatten)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(flatten)\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    z = layers.Lambda(sampling, name='z')([z_mean, z_log_var])\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "    # Decoder\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    # Ajusta o tamanho da camada densa para corresponder ao novo latent_dim e √†s camadas do encoder\n",
    "    x = layers.Dense(32 * 32 * 32, activation='relu')(latent_inputs)\n",
    "    x = layers.Reshape((32, 32, 32))(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', strides=(2, 2), padding='same')(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', strides=(2, 2), padding='same')(x)\n",
    "    outputs = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    vae = VAE(encoder, decoder, beta=beta) \n",
    "    vae.compile(optimizer='adam', loss='mean_squared_error') \n",
    "    return vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AE Redund√¢ncia Inicial\n",
    "\n",
    "- üîß Hiperpar√¢metros\n",
    "- Input Image Shape: 128 x 128 x 3\n",
    "- Encoder layers: 2x(conv2d +  maxpooling) + FLaten\n",
    "- Decoder layers: Dense + Reshape+  upsampling  + Conv2d\n",
    "- Activation function: relu + sigmoid\n",
    "- Optimizer: Adam\n",
    "- Loss function: MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Modelo Inicial\n",
    "def criar_autoencoder_redundancia(input_shape=(128,128,3)):\n",
    "    inp = Input(shape=input_shape, name='pen_input')\n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inp)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "    x = layers.Conv2D(16, 3, activation='relu', padding='same')(x)\n",
    "    encoded = layers.MaxPooling2D(2, padding='same')(x)\n",
    "\n",
    "    flat = layers.Flatten()(encoded)\n",
    "    penal = layers.Dense(\n",
    "        256,\n",
    "        activity_regularizer=tf.keras.regularizers.l1(1e-5),\n",
    "        name='encoded_penalizado'\n",
    "    )(flat)\n",
    "\n",
    "    x = layers.Dense(32*32*16, activation='relu')(penal)\n",
    "    x = layers.Reshape((32,32,16))(x)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = layers.Conv2D(16, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    out = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoenc_pen = Model(inp, out, name='autoencoder_redundancia')\n",
    "    autoenc_pen.compile(optimizer='adam', loss='mse')\n",
    "    return autoenc_pen\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AE Redund√¢ncia Melhorado\n",
    "- apenas duas trocas: L1 menor e latente maior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_autoencoder_redundancia_melhorado(input_shape=(128,128,3), latent_dim=512, l1_reg=1e-6):\n",
    "    input_img = Input(shape=input_shape, name='pen_input')\n",
    "    x = layers.Conv2D(64, 3, padding='same')(input_img)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.1)(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)  # 64x64\n",
    "\n",
    "    x = layers.Conv2D(32, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.1)(x)\n",
    "    encoded_conv = layers.MaxPooling2D(2, padding='same')(x)  # 32x32\n",
    "\n",
    "    encoded_flat = layers.Flatten()(encoded_conv)\n",
    "    latent = layers.Dense(\n",
    "        latent_dim,  # 128 -> 512/1024\n",
    "        activation='relu',\n",
    "        activity_regularizer=tf.keras.regularizers.l1(l1_reg)  # 10e-5 (1e-4) -> 1e-6\n",
    "    )(encoded_flat)\n",
    "\n",
    "    x = layers.Dense(32 * 32 * 32, activation='relu')(latent)\n",
    "    x = layers.Reshape((32, 32, 32))(x)\n",
    "    x = layers.Conv2DTranspose(32, 3, strides=2, padding='same', activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.1)(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.1)(x)\n",
    "\n",
    "    out = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    m = Model(input_img, out, name='autoencoder_redundancia_melhorado')\n",
    "    m.compile(optimizer='adam', loss='mse')\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento e avalia√ß√£o Otimizado\n",
    "\n",
    "- üîß Hiperpar√¢metros e configura√ß√µes\n",
    "- Quantidade de √©pocas: 800 (definido ap√≥s rodar o EarlyStopping)\n",
    "- Earlystopping: √© um callback que interrompe o treinamento quando a m√©trica monitorada (no caso, a val_loss) para de melhorar. Isso impede que o modelo continue treinando e comece a \"memorizar\" os dados de treinamento (overfitting).\n",
    "- Learning Rate Scheduler: acelera a converg√™ncia e ajuda a alcan√ßar erro mais baixo/est√°vel\n",
    "- Adicionado c√°lculo de passos por √©pocas\n",
    "- Salva cada modelo por hor√°rio e para facilitar em uma pasta models\n",
    "- batch size: 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifica√ß√µes antes do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Formato dos dados de valida√ß√£o (X_val): {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agora = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "print(agora)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e avalia√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lw8JEAzmPN4l",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fun√ß√£o de treinamento e avalia√ß√£o com Learning Rate Scheduler\n",
    "def treinar_e_avaliar_melhorado(modelo, nome, train_data, val_data, test_data):\n",
    "    # Callback para Early Stopping\n",
    "    monitor = 'val_loss'\n",
    "    mode = 'min'\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=monitor,\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        mode=mode\n",
    "    )\n",
    "    # Callback para Learning Rate Scheduler\n",
    "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=monitor,\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1,\n",
    "        mode=mode\n",
    "    )\n",
    "    # Treina o modelo\n",
    "    batch_size = 32\n",
    "    # Calcule o n√∫mero de passos por √©poca\n",
    "    steps_per_epoch_train = int(np.ceil(train_data.shape[0] / batch_size))\n",
    "    steps_per_epoch_val = int(np.ceil(val_data.shape[0] / batch_size))\n",
    "    # Treina o modelo\n",
    "    history = modelo.fit(\n",
    "        X_train,\n",
    "        X_train,\n",
    "        epochs=800,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, X_val),\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping, lr_scheduler],\n",
    "        steps_per_epoch=steps_per_epoch_train,\n",
    "        validation_steps=steps_per_epoch_val\n",
    "    )\n",
    "    \n",
    "    # --- Configura√ß√£o de Caminho e Nome de Arquivo ---\n",
    "    # 1. Crie a pasta 'plots/' se ela n√£o existir\n",
    "    if not os.path.exists('plots'):\n",
    "        os.makedirs('plots')\n",
    "    # 2. Obtenha a data e hora atuais para o nome do arquivo\n",
    "    agora = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # --- PLOTAGEM E SALVAMENTO do Gr√°fico de LOSS PRINCIPAL ---\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='Loss de Treinamento')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Loss de Valida√ß√£o')\n",
    "    elif 'val_total_loss' in history.history:\n",
    "        plt.plot(history.history['val_total_loss'], label='Loss de Valida√ß√£o')\n",
    "    \n",
    "    plt.title(f'Hist√≥rico de Treinamento - {nome}')\n",
    "    plt.xlabel('√âpocas')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # SALVAR o gr√°fico de Loss principal\n",
    "    caminho_loss = f'plots/{nome}_Loss_{agora}.png'\n",
    "    plt.savefig(caminho_loss)\n",
    "    plt.close() # Fecha a figura para liberar mem√≥ria\n",
    "    print(f\"Gr√°fico de Loss principal salvo em: {caminho_loss}\")\n",
    "\n",
    "    # --- PLOTAGEM E SALVAMENTO do Gr√°fico de KL LOSS (para Variacional) ---\n",
    "    # Para os modelos Variacional, que t√™m perdas adicionais:\n",
    "    if 'kl_loss' in history.history:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(history.history['kl_loss'], label='KL Loss')\n",
    "        if 'val_kl_loss' in history.history:\n",
    "            plt.plot(history.history['val_kl_loss'], label='Valida√ß√£o KL Loss')\n",
    "        \n",
    "        plt.title(f'Hist√≥rico da Perda de KL Divergence - {nome}')\n",
    "        plt.xlabel('√âpocas')\n",
    "        plt.ylabel('KL Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # SALVAR o gr√°fico de KL Loss\n",
    "        caminho_kl = f'plots/{nome}_KLLoss_{agora}.png'\n",
    "        plt.savefig(caminho_kl)\n",
    "        plt.close() # Fecha a figura para liberar mem√≥ria\n",
    "        print(f\"Gr√°fico de KL Loss salvo em: {caminho_kl}\")\n",
    "        \n",
    "    # --- Salvar o modelo em uma pasta \"models\" com data e hora ---\n",
    "    # 1. Crie a pasta 'models/' se ela n√£o existir\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    # 2. Obtenha a data e hora atuais para o nome do arquivo (j√° temos 'agora')\n",
    "    nome_do_arquivo = f'models/{nome}_{agora}.keras'\n",
    "    # 3. Salve o modelo treinado\n",
    "    modelo.save(nome_do_arquivo)\n",
    "    print(f\"Modelo salvo em: {nome_do_arquivo}\")\n",
    "\n",
    "    # Coleta as m√©tricas de avalia√ß√£o\n",
    "    psnr_total, ssim_total, ms_ssim_total, tempo_total = 0, 0, 0, 0\n",
    "    num_test_images = test_data.shape[0]\n",
    "    for i in range(num_test_images):\n",
    "        entrada = np.expand_dims(test_data[i], axis=0)\n",
    "        inicio = time.time()\n",
    "        saida = modelo.predict(entrada, verbose=0)\n",
    "        fim = time.time()\n",
    "        tempo_total += fim - inicio\n",
    "        psnr_total += tf.image.psnr(tf.image.convert_image_dtype(entrada, dtype=tf.float32),\n",
    "                                     tf.image.convert_image_dtype(saida, dtype=tf.float32),\n",
    "                                     max_val=1.0).numpy()[0]\n",
    "        ssim_total += ssim(entrada[0], saida[0], data_range=1.0, channel_axis=2)\n",
    "    ms_ssim_total += tf.image.ssim_multiscale(\n",
    "        tf.image.convert_image_dtype(entrada, dtype=tf.float32),\n",
    "        tf.image.convert_image_dtype(saida, dtype=tf.float32),\n",
    "        max_val=1.0,\n",
    "        filter_size=3\n",
    "        \n",
    "    ).numpy()[0]\n",
    "\n",
    "    return psnr_total/num_test_images, ssim_total/num_test_images, ms_ssim_total/num_test_images, tempo_total/num_test_images\n",
    "\n",
    "# Cria√ß√£o e Treinamento dos modelos melhorados\n",
    "with strategy.scope():    \n",
    "    modelos = {\n",
    "        'Convencional': criar_autoencoder(),\n",
    "        #'Variacional': criar_vae(),\n",
    "        #'Redund√¢ncia': criar_autoencoder_redundancia(),\n",
    "        #'ConvencionalOtimizado': criar_autoencoder_melhorado(), \n",
    "        #'VariacionalOtimizado': criar_vae_melhorado(latent_dim=128,beta=0.01),\n",
    "        #'Redund√¢nciaOtimizado': criar_autoencoder_redundancia_melhorado(latent_dim=512,l1_reg=1e-6)\n",
    "    }\n",
    "\n",
    "resultados = {}\n",
    "for nome, modelo in modelos.items():\n",
    "    print(f\"\\nTreinando e avaliando o modelo: {nome}\")\n",
    "    psnr, ssim_val, ms_ssim_val, tempo = treinar_e_avaliar_melhorado(modelo, nome, X_train, X_val, X_test)\n",
    "    resultados[nome] = {\n",
    "        'PSNR': psnr,\n",
    "        'SSIM': ssim_val,\n",
    "        'MS-SSIM': ms_ssim_val,\n",
    "        'Tempo (s)': tempo\n",
    "    }\n",
    "\n",
    "print(\"\\n--- Resultados Finais ---\")\n",
    "for nome, metricas in resultados.items():\n",
    "    print(f\"\\nModelo: {nome}\")\n",
    "    for metrica, valor in metricas.items():\n",
    "        print(f\"  {metrica}: {valor:.4f}\")\n",
    "\n",
    "# --- Bloco de Salvamento em Arquivo TXT (APPEND) ---\n",
    "\n",
    "# 1. Defina o nome do arquivo de log (FIXO, sem data/hora no nome)\n",
    "arquivo_log = os.path.join(\"results\", \"historico_metricas_treinamento.txt\")\n",
    "\n",
    "# 2. Crie a pasta 'results' se ela n√£o existir\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# 3. Obtenha a data e hora atual\n",
    "agora = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# 4. Abra o arquivo no modo 'a' (append) para adicionar conte√∫do\n",
    "with open(arquivo_log, \"a\", encoding=\"utf-8\") as f:\n",
    "    \n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "    f.write(f\"Registro de Treinamento: {agora}\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Itera sobre os resultados de todos os modelos\n",
    "    for nome, metricas in resultados.items():\n",
    "        \n",
    "        # Inicia a linha com o nome do modelo\n",
    "        f.write(f\"Modelo: {nome}\\n\")\n",
    "        \n",
    "        # Itera sobre as m√©tricas do modelo\n",
    "        for metrica, valor in metricas.items():\n",
    "            \n",
    "            # Formata a m√©trica (com 4 casas decimais)\n",
    "            try:\n",
    "                valor_formatado = f\"{float(valor):.4f}\"\n",
    "            except Exception:\n",
    "                valor_formatado = str(valor) # Caso n√£o seja um n√∫mero\n",
    "            \n",
    "            # Escreve a m√©trica formatada\n",
    "            f.write(f\"  {metrica}: {valor_formatado}\\n\")\n",
    "            \n",
    "        f.write(\"-\" * 25 + \"\\n\") # Separador entre modelos\n",
    "\n",
    "print(f\"Hist√≥rico de m√©tricas salvo em: {arquivo_log}\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando valores das  m√©tricas\n",
    "# Criar pasta results se n√£o existir\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Nome do arquivo com data e hora\n",
    "agora = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "arquivo_saida = os.path.join(\"results\", f\"resultados_metricas_{agora}.csv\")\n",
    "\n",
    "# Salvar em CSV\n",
    "with open(arquivo_saida, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # Cabe√ßalho\n",
    "    metricas_existentes = list(next(iter(resultados.values())).keys())\n",
    "    writer.writerow([\"Modelo\"] + metricas_existentes)\n",
    "\n",
    "    # Linhas de dados\n",
    "    for nome, metricas in resultados.items():\n",
    "        linha = [nome]\n",
    "        for m in metricas_existentes:\n",
    "            valor = metricas[m]\n",
    "            try:\n",
    "                linha.append(f\"{float(valor):.4f}\")\n",
    "            except Exception:\n",
    "                linha.append(valor)\n",
    "        writer.writerow(linha)\n",
    "\n",
    "print(f\"Resultados salvos em: {arquivo_saida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lise de resultados\n",
    "\n",
    "- üîß M√©tricas\n",
    "- Para a avalia√ß√£o da qualidade das imagens reconstru√≠das, foram utilizadas tr√™s m√©tricas amplamente reconhecidas na literatura: [Ramos et al., 2023], [Wang et al., 2004] [Wang et al., 2003]\n",
    "\n",
    "PSNR (Peak Signal-to-Noise Ratio)\n",
    ">O PSNR √© uma m√©trica de fidelidade que compara o pixel a pixel da imagem original com a imagem reconstru√≠da. Um valor mais alto indica melhor qualidade.\n",
    "\n",
    "SSIM (Structural Similarity Index)\n",
    ">O SSIM √© uma m√©trica que considera a lumin√¢ncia, o contraste e a estrutura da imagem. Seu valor varia de -1 a 1, onde 1 indica uma similaridade perfeita.\n",
    "\n",
    "MS-SSIM (Multi-Scale Structural Similarity Index)\n",
    ">O MS-SSIM √© uma extens√£o do SSIM que avalia a similaridade em v√°rias escalas de imagem, o que geralmente se alinha ainda melhor com a percep√ß√£o humana. Seu valor tamb√©m varia de -1 a 1.\n",
    "> Fontes\n",
    "- Ramos, G. S., Lima, A. A., Almeida, L. F., Lima, J., & Pinto, M. F. (2023). Simulation and evaluation of deep learning autoencoders for image compression in multi-UAV network systems. In LARS, SBR, WRE. IEEE. https://doi.org/10.1109/LARS/SBR/WRE59448.2023.10332986\n",
    "- Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image Quality Assessment: From Error Visibility to Structural Similarity. IEEE Transactions on Image Processing, 13(4), 600‚Äì612. https://doi.org/10.1109/TIP.2003.819128\n",
    "- Wang, Z., Simoncelli, E. P., & Bovik, A. C. (2003). Multiscale structural similarity for image quality assessment. In The Thirty-Seventh Asilomar Conference on Signals, Systems and Computers, 2003 (Vol. 2, pp. 1398‚Äì1402). IEEE. https://doi.org/10.1109/ACSSC.2003.1294653"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ler dados do arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_resultados_do_arquivo(nome_arquivo):\n",
    "    \"\"\"\n",
    "    L√™ o arquivo de hist√≥rico de m√©tricas e retorna o dicion√°rio 'resultados'.\n",
    "    \"\"\"\n",
    "    resultados = {}\n",
    "    \n",
    "    try:\n",
    "        with open(nome_arquivo, 'r') as f:\n",
    "            conteudo = f.read()\n",
    "            \n",
    "        # Divide o conte√∫do em blocos, usando o separador \"Modelo: \"\n",
    "        blocos = conteudo.split('Modelo: ')[1:]\n",
    "        \n",
    "        for bloco in blocos:\n",
    "            linhas = bloco.strip().split('\\n')\n",
    "            \n",
    "            # O nome do modelo √© a primeira linha\n",
    "            nome_modelo = linhas[0].strip()\n",
    "            \n",
    "            # Inicializa o dicion√°rio para este modelo\n",
    "            resultados[nome_modelo] = {}\n",
    "            \n",
    "            # Itera sobre as linhas de m√©tricas (come√ßando da segunda linha)\n",
    "            for linha in linhas[1:]:\n",
    "                if ':' in linha:\n",
    "                    # Ex: '  PSNR: 17.6680'\n",
    "                    parte, valor_str = linha.split(':')\n",
    "                    metrica = parte.strip().replace(' (s)', '') # Limpa o nome da m√©trica\n",
    "                    \n",
    "                    try:\n",
    "                        # Converte o valor para float\n",
    "                        valor = float(valor_str.strip())\n",
    "                        \n",
    "                        # Adiciona ao dicion√°rio, usando o nome completo da m√©trica\n",
    "                        if metrica == 'Tempo':\n",
    "                            metrica = 'Tempo (s)'\n",
    "                        \n",
    "                        resultados[nome_modelo][metrica] = valor\n",
    "                    except ValueError:\n",
    "                        # Ignora linhas onde a convers√£o para float falhou\n",
    "                        continue\n",
    "                        \n",
    "        return resultados\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå ERRO: Arquivo '{nome_arquivo}' n√£o encontrado.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERRO ao processar o arquivo: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gr√°ficos comparativos das m√©tricas PNSR, SSIM, MS-SIM, Tempo m√©dios. Paras os  modelos Convencional, Variacional, Redund√¢ncia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOME_ARQUIVO_METRICAS = 'results/historico_metricas_treinamento.txt' \n",
    "resultados = ler_resultados_do_arquivo(NOME_ARQUIVO_METRICAS)\n",
    "\n",
    "if resultados is None:\n",
    "    exit()  \n",
    "\n",
    "df = pd.DataFrame.from_dict(resultados, orient='index').reset_index().rename(columns={'index': 'Modelo'})\n",
    "\n",
    "# PADRONIZA√á√ÉO DOS R√ìTULOS\n",
    "df['Modelo'] = df['Modelo'].replace({\n",
    "    'Convencional': 'Convencional (Base)',\n",
    "    'Variacional': 'Variacional (Base)',\n",
    "    'Redund√¢ncia': 'Redund√¢ncia (Base)',\n",
    "    'ConvencionalOtimizado': 'Convencional Otimizado (FINAL)',\n",
    "    'VariacionalOtimizado': 'Variacional Otimizado (FINAL)',\n",
    "    'Redund√¢nciaOtimizado': 'Redund√¢ncia Otimizado (FINAL)',\n",
    "})\n",
    "\n",
    "# ... C√≥digo de exporta√ß√£o CSV (mantido) ...\n",
    "NOME_ARQUIVO_CSV = 'results/comparativo_final_metricas.csv'\n",
    "def obter_configuracao(modelo):\n",
    "    if 'Variacional' in modelo and 'FINAL' in modelo: return 'beta=0.01, L=128'\n",
    "    if 'Redund√¢ncia' in modelo and 'FINAL' in modelo: return 'l1_reg=1e-6, L=512'\n",
    "    return '---'\n",
    "\n",
    "df['Configura√ß√£o Otimizada'] = df['Modelo'].apply(obter_configuracao)\n",
    "df.to_csv(NOME_ARQUIVO_CSV, index=False, decimal='.')\n",
    "print(f\"Tabela de dados exportada para CSV: {NOME_ARQUIVO_CSV}\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# C√ìDIGO DE PLOTAGEM (LAYOUT 4x1 com Legenda no Topo e Maior Altura)\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "labels = df['Modelo'].tolist()\n",
    "psnr_vals    = df['PSNR'].tolist()\n",
    "ssim_vals    = df['SSIM'].tolist()\n",
    "ms_ssim_vals = df['MS-SSIM'].tolist()\n",
    "tempo_vals   = df['Tempo (s)'].tolist()\n",
    "\n",
    "cores = plt.cm.tab10(np.linspace(0, 1, len(labels)))\n",
    "\n",
    "# AUMENTO DA ALTURA: figsize=(14, 16) para dar mais espa√ßo vertical a cada gr√°fico.\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 16), sharex=False) \n",
    "axs = axes.flatten()\n",
    "\n",
    "metricas = [psnr_vals, ssim_vals, ms_ssim_vals, tempo_vals]\n",
    "titulos  = ['PSNR M√©dio (dB)', 'SSIM M√©dio', 'MS-SSIM M√©dio', 'Tempo M√©dio (s)']\n",
    "# Limites Y\n",
    "limites_y = [\n",
    "    (10.0, 22.0),  # PSNR\n",
    "    (0.0, 1.0),    # SSIM\n",
    "    (0.0, 1.0),    # MS-SSIM\n",
    "    (0.20, 0.35)   # Tempo\n",
    "]\n",
    "\n",
    "barras_para_legenda = None \n",
    "\n",
    "for i, (ax, valores, titulo) in enumerate(zip(axs, metricas, titulos)):\n",
    "    barras = ax.bar(labels, valores, color=cores)\n",
    "    ax.set_title(titulo)\n",
    "    \n",
    "    if barras_para_legenda is None:\n",
    "        barras_para_legenda = barras\n",
    "    \n",
    "    ax.set_ylim(limites_y[i])\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels([]) # Remove r√≥tulos dos modelos\n",
    "    \n",
    "    # Colocar Valores Acima das Barras\n",
    "    for bar in barras:\n",
    "        yval = bar.get_height()\n",
    "        formato = '.4f'\n",
    "        ax.text(bar.get_x() + bar.get_width()/2.0, bar.get_height() + ax.get_ylim()[1] * 0.015, \n",
    "                f'{yval:{formato}}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# CRIA A LEGENDA CENTRALIZADA ACIMA DE TODOS OS GR√ÅFICOS\n",
    "fig.legend(barras_para_legenda, labels, \n",
    "           title=\"Modelos\", \n",
    "           loc='upper center', \n",
    "           bbox_to_anchor=(0.5, 1.02), # Ajuste fino da posi√ß√£o vertical\n",
    "           ncol=3, \n",
    "           fontsize=10)\n",
    "\n",
    "# Ajusta o layout (o rect √© crucial para a legenda superior)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# SALVAMENTO DO GR√ÅFICO\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "NOME_PASTA = 'plots'\n",
    "agora = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "nome_arquivo_completo = f'{NOME_PASTA}/Comparativo_Modelos_4x1_Final_{agora}.p'\n",
    "\n",
    "try:\n",
    "    os.makedirs(NOME_PASTA, exist_ok=True)\n",
    "    fig.savefig(nome_arquivo_completo, bbox_inches='tight', dpi=600) \n",
    "    print(f\"Gr√°fico comparativo (4x1, altura ajustada) salvo em: {nome_arquivo_completo}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao salvar o gr√°fico: {e}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstru√ß√£o de uma amostra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_reconstrucao(idx):\n",
    "    orig = X_test[idx]\n",
    "    entrada = orig[np.newaxis]\n",
    "\n",
    "    for nome, modelo in modelos.items():\n",
    "        recon = modelo.predict(entrada, verbose=0)[0]\n",
    "\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(orig)\n",
    "        plt.title('Original')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(recon)\n",
    "        plt.title(f'Reconstru√ß√£o: {nome}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.suptitle(f'Amostra {idx}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Exemplo de uso\n",
    "mostrar_reconstrucao(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste estat√≠stico Kruskal-Wallis\n",
    "O teste de Kruskal-Wallis, que est√° no seu c√≥digo, √© a ferramenta estat√≠stica correta para comparar essas m√©tricas entre os modelos e determinar se h√° uma diferen√ßa estatisticamente significativa entre eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Fun√ß√£o auxiliar que retorna as listas de m√©tricas para um modelo\n",
    "def coletar_metricas(modelo, n_amostras=50):\n",
    "    psnr_list    = []\n",
    "    ssim_list    = []\n",
    "    ms_ssim_list = []\n",
    "\n",
    "    # j√° treinou antes, mas podemos retreinar r√°pido para alinhar com o split\n",
    "    modelo.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=5, batch_size=32,\n",
    "        validation_data=(X_val, X_val),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    for i in range(n_amostras):\n",
    "        entrada = np.expand_dims(X_test[i], axis=0)\n",
    "        saida   = modelo.predict(entrada, verbose=0)\n",
    "\n",
    "        # acumula cada valor\n",
    "        psnr_list.append(\n",
    "            tf.image.psnr(entrada, saida, max_val=1.0).numpy()[0]\n",
    "        )\n",
    "        ssim_list.append(\n",
    "            ssim(entrada[0], saida[0], data_range=1.0, channel_axis=2)\n",
    "        )\n",
    "        ms_ssim_list.append(\n",
    "            tf.image.ssim_multiscale(\n",
    "                entrada, saida,\n",
    "                max_val=1.0,\n",
    "                filter_size=3\n",
    "            ).numpy()[0]\n",
    "        )\n",
    "\n",
    "    return psnr_list, ssim_list, ms_ssim_list\n",
    "    \n",
    "model_conv = tf.keras.models.load_model('models/ConvencionalOtimizado.keras')\n",
    "model_vae = tf.keras.models.load_model('models/VariacionalOtimizado.keras', custom_objects={'VAE': VAE})\n",
    "model_red = tf.keras.models.load_model('models/Redund√¢nciaOtimizado.keras')\n",
    "\n",
    "\n",
    "# 2) Coleta as m√©tricas para cada modelo\n",
    "psnr_conv, ssim_conv, ms_ssim_conv = coletar_metricas(modelos['Convencional'])\n",
    "psnr_var,  ssim_var,  ms_ssim_var  = coletar_metricas(modelos['Variacional'])\n",
    "psnr_red,  ssim_red,  ms_ssim_red  = coletar_metricas(modelos['Redund√¢ncia'])\n",
    "\n",
    "# 3) Teste de Kruskal-Wallis em cada m√©trica\n",
    "stat_psnr, p_psnr   = kruskal(psnr_conv, psnr_var, psnr_red)\n",
    "stat_ssim, p_ssim   = kruskal(ssim_conv, ssim_var, ssim_red)\n",
    "stat_msss, p_msss   = kruskal(ms_ssim_conv, ms_ssim_var, ms_ssim_red)\n",
    "\n",
    "print(\"Kruskal-Wallis Results:\")\n",
    "print(f\"  PSNR   ‚Üí H = {stat_psnr:.3f}, p = {p_psnr:.4f}\")\n",
    "print(f\"  SSIM   ‚Üí H = {stat_ssim:.3f}, p = {p_ssim:.4f}\")\n",
    "print(f\"  MS-SSIM‚Üí H = {stat_msss:.3f}, p = {p_msss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiza√ß√£o dos hiperpar√¢metros dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coletar_metricas(modelo, n_amostras=10):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "\n",
    "    psnr_list, ssim_list, ms_ssim_list = [], [], []\n",
    "\n",
    "    for _ in range(n_amostras):\n",
    "        # gere (entrada, saida) conforme o seu pipeline\n",
    "        # exemplo (ajuste para o seu caso):\n",
    "        entrada = tf.random.uniform((1, 128, 128, 3), 0.0, 1.0, dtype=tf.float32)\n",
    "        saida   = modelo(entrada, training=False)\n",
    "\n",
    "        psnr_list.append(tf.image.psnr(entrada, saida, max_val=1.0).numpy()[0])\n",
    "\n",
    "        # ssim do skimage trabalha com arrays 2D/3D, ent√£o remova o batch dim\n",
    "        entrada_np = entrada.numpy()[0]\n",
    "        saida_np   = saida.numpy()[0]\n",
    "        ssim_list.append(\n",
    "            ssim(entrada_np, saida_np, data_range=1.0, channel_axis=2)\n",
    "        )\n",
    "\n",
    "        ms_ssim_list.append(\n",
    "            tf.image.ssim_multiscale(entrada, saida, max_val=1.0).numpy()[0]\n",
    "        )\n",
    "\n",
    "    return psnr_list, ssim_list, ms_ssim_list\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 1) Carregamento Din√¢mico dos Modelos Otimizados\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "MODELS_DIR = 'models'\n",
    "# Dicion√°rio que armazenar√° os modelos carregados {nome_base: objeto_modelo}\n",
    "modelos_otimizados = {}\n",
    "# Custom objects necess√°rios para carregar o modelo VAE\n",
    "CUSTOM_OBJECTS = {'VAE': VAE} \n",
    "\n",
    "print(f\"Buscando modelos otimizados em: {MODELS_DIR}\")\n",
    "for filename in os.listdir(MODELS_DIR):\n",
    "    # Filtra apenas os arquivos .keras ou .h5 que s√£o Otimizados\n",
    "    if ('Otimizado' in filename) and (filename.endswith('.keras') or filename.endswith('.h5')):\n",
    "        \n",
    "        # Extrai o nome base (ex: 'Convencional' de 'ConvencionalOtimizado.keras')\n",
    "        nome_completo = filename.split('.')[0]\n",
    "        nome_base = nome_completo.replace('Otimizado', '')\n",
    "        caminho_completo = os.path.join(MODELS_DIR, filename)\n",
    "        \n",
    "        try:\n",
    "            # Condi√ß√£o especial para o modelo Variacional (que requer 'VAE')\n",
    "            if 'Variacional' in nome_completo:\n",
    "                modelo = tf.keras.models.load_model(caminho_completo, custom_objects=CUSTOM_OBJECTS)\n",
    "                print(f\"   ‚úì Carregado: {nome_completo} (com VAE custom)\")\n",
    "            else:\n",
    "                # Carregamento padr√£o\n",
    "                modelo = tf.keras.models.load_model(caminho_completo)\n",
    "                print(f\"   ‚úì Carregado: {nome_completo}\")\n",
    "                \n",
    "            modelos_otimizados[nome_base] = modelo\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Erro ao carregar {filename}: {e}\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 2) Coleta e Teste Estat√≠stico (Usando o dicion√°rio din√¢mico)\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Inicializa as listas para os testes estat√≠sticos\n",
    "psnr_lists = []\n",
    "ssim_lists = []\n",
    "ms_ssim_lists = []\n",
    "nomes_modelos = []\n",
    "\n",
    "print(\"\\nColetando m√©tricas por amostragem...\")\n",
    "for nome, modelo in modelos_otimizados.items():\n",
    "    # Coleta as m√©tricas usando a fun√ß√£o auxiliar\n",
    "    psnr, ssim, msss = coletar_metricas(modelo)\n",
    "    \n",
    "    # Armazena as listas de m√©tricas na ordem de coleta\n",
    "    psnr_lists.append(psnr)\n",
    "    ssim_lists.append(ssim)\n",
    "    ms_ssim_lists.append(msss)\n",
    "    nomes_modelos.append(nome)\n",
    "\n",
    "print(f\"Modelos comparados: {', '.join([n + ' Otimizado' for n in nomes_modelos])}\")\n",
    "\n",
    "# 3) Teste de Kruskal-Wallis em cada m√©trica\n",
    "# Usa o operador * (desempacotamento) para passar todas as listas como argumentos separados\n",
    "stat_psnr, p_psnr = kruskal(*psnr_lists)\n",
    "stat_ssim, p_ssim = kruskal(*ssim_lists)\n",
    "stat_msss, p_msss = kruskal(*ms_ssim_lists)\n",
    "\n",
    "print(\"\\nKruskal-Wallis Results:\")\n",
    "print(f\"  PSNR    ‚Üí H = {stat_psnr:.3f}, p = {p_psnr:.4f}\")\n",
    "print(f\"  SSIM    ‚Üí H = {stat_ssim:.3f}, p = {p_ssim:.4f}\")\n",
    "print(f\"  MS-SSIM ‚Üí H = {stat_msss:.3f}, p = {p_msss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge\n",
    "- pip install edgeimpulse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantiza√ß√£o int8 e gera√ß√£o do arquivo npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantiza√ß√£o isolada\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from typing import Iterator, List, Any\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# --- CONFIGURA√á√ïES E CAMINHOS ---\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# üö® AJUSTE ESTE CAMINHO PARA O SEU MODELO 32x32 TREINADO\n",
    "MODEL_PATH = 'models/Convencional_2025-10-18_12-05-32.keras' \n",
    "\n",
    "# Arquivos de sa√≠da\n",
    "TFLITE_OUTPUT_FILE = 'autoencoder_conv_INT8_32x32.tflite'\n",
    "NPY_OUTPUT_FILE = 'representative_features_32x32.npy'\n",
    "OUTPUT_DIR = 'edgeimpulse_deployment'\n",
    "NUM_SAMPLES = 200 # N√∫mero de amostras para quantiza√ß√£o\n",
    "\n",
    "# Inicializa√ß√£o de vari√°veis de caminho\n",
    "tflite_output_path = os.path.join(OUTPUT_DIR, TFLITE_OUTPUT_FILE)\n",
    "npy_output_path = os.path.join(OUTPUT_DIR, NPY_OUTPUT_FILE)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. PREPARA√á√ÉO DOS DADOS REPRESENTATIVOS (Obrigat√≥rio para INT8)\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"--- 1. Preparando Dados Representativos ---\")\n",
    "\n",
    "try:\n",
    "    # üö® ATEN√á√ÉO: SUBSTITUA PELA L√ìGICA CORRETA PARA CARREGAR SEUS DADOS\n",
    "    # O exemplo assume que seus dados de treinamento (X_train) foram redimensionados para 32x32.\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # *** EXEMPLO DE DADOS PLACEHOLDER - VOC√ä DEVE SUBSTITUIR ESTE BLOCO ***\n",
    "    # Supondo que a imagem de entrada √© 32x32x3 e os dados est√£o em float32 [0.0, 1.0]\n",
    "    # Seus dados devem estar carregados na mem√≥ria, ex: X_train\n",
    "    # Para teste, usamos dados aleat√≥rios com o formato correto:\n",
    "    IMAGE_SIZE = 32\n",
    "    X_quant_sample = np.random.rand(NUM_SAMPLES, IMAGE_SIZE, IMAGE_SIZE, 3).astype(np.float32)\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    \n",
    "    if X_quant_sample.max() > 1.05 or X_quant_sample.min() < -0.05:\n",
    "        # Garante que a faixa seja 0.0-1.0\n",
    "        X_quant_sample = X_quant_sample.astype(np.float32) / 255.0\n",
    "\n",
    "    print(f\"Dados de quantiza√ß√£o carregados: {X_quant_sample.shape} (Float32, 0.0-1.0)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO ao preparar dados: {e}. Verifique o carregamento de X_train/X_val.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "def representative_data_gen() -> Iterator[List[tf.Tensor]]:\n",
    "    \"\"\"Gera dados de amostra para o TFLite Converter.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(X_quant_sample)\n",
    "    \n",
    "    # O .take() garante o fim da sequ√™ncia (resolvendo o erro OUT_OF_RANGE)\n",
    "    for input_value in dataset.batch(1).take(NUM_SAMPLES):\n",
    "        yield [tf.cast(input_value, tf.float32)]\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. CONVERS√ÉO E QUANTIZA√á√ÉO INT8\n",
    "# ----------------------------------------------------------------------\n",
    "conversion_success = False\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    # 1. Carregar o modelo Keras \n",
    "    model = keras.models.load_model(MODEL_PATH) \n",
    "    \n",
    "    print(\"\\n--- 2. Iniciando Convers√£o para INT8 ---\")\n",
    "    \n",
    "    # --- AJUSTE CR√çTICO DE AMBIENTE: RESOLVE O ERRO DE GPU/MLIR/FLEX ---\n",
    "    # Desabilita otimiza√ß√µes que causam erros de operador no TFLite INT8\n",
    "    os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "    tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "    # 2. Instanciar o Converter\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    \n",
    "    # 3. Configura√ß√µes de Quantiza√ß√£o INT8\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_gen \n",
    "    \n",
    "    # For√ßa a usar TFLITE_BUILTINS_INT8 (o conjunto de operadores mais r√°pido)\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "    \n",
    "    tflite_model_quantized = converter.convert()\n",
    "\n",
    "    # 4. Salvar o TFLite\n",
    "    with open(tflite_output_path, 'wb') as f:\n",
    "        f.write(tflite_model_quantized)\n",
    "        \n",
    "    print(f\"‚úÖ Modelo TFLite INT8 salvo em: {tflite_output_path}\")\n",
    "    conversion_success = True \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERRO FATAL na convers√£o INT8: {e}\")\n",
    "    print(\"A convers√£o falhou. O modelo cont√©m operadores incompat√≠veis (Flex/MLIR) para INT8 puro.\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. GERAR O ARQUIVO .NPY E IMPRIMIR PR√ìXIMOS PASSOS\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"\\n--- 3. Gera√ß√£o do NPY e Instru√ß√µes Finais ---\")\n",
    "try:\n",
    "    np.save(npy_output_path, X_quant_sample)\n",
    "    print(f\"‚úÖ Arquivo de dados representativos .npy salvo em: {npy_output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao salvar arquivo .npy: {e}\")\n",
    "\n",
    "# IMPRESS√ÉO FINAL (Condicional)\n",
    "if conversion_success:\n",
    "    print(\"\\n[INSTRU√á√ïES PARA EDGE IMPULSE]\")\n",
    "    print(\"O modelo foi quantizado com sucesso.\")\n",
    "    print(f\"Carregue o arquivo .tflite diretamente: '{tflite_output_path}'\")\n",
    "else:\n",
    "    print(\"\\n[INSTRU√á√ïES PARA EDGE IMPULSE - FALHA]\")\n",
    "    print(\"A convers√£o INT8 local falhou. Voc√™ tem duas op√ß√µes:\")\n",
    "    print(\"1. Tente simplificar a arquitetura (menos filtros) e repita.\")\n",
    "    print(\"2. Carregue o .npy e o SavedModel.zip no Edge Impulse, esperando que o compilador do servidor resolva o problema de operador.\")\n",
    "    print(f\"   Arquivo .npy: '{npy_output_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantiza√ß√£o\n",
    "# --- Configura√ß√µes ---\n",
    "INPUT_DIR = \"models\"\n",
    "OUTPUT_DIR = \"edgeimpulse_models\"\n",
    "TEMP_DIR_BASE = os.path.join(OUTPUT_DIR, \"temp_processing\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. FUN√á√ïES E CLASSES CUSTOMIZADAS\n",
    "# INCLUINDO A CLASSE VAE E A FUN√á√ÉO SAMPLING (CRUCIAIS)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Sua fun√ß√£o 'sampling'\n",
    "@register_keras_serializable(package=\"CustomVAE\")\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick for Variational Autoencoder.\"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    # Usa tf.random.normal para evitar depend√™ncia do K.\n",
    "    epsilon = tf.random.normal(shape=(batch, dim)) \n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Sua classe VAE (keras.Model customizada)\n",
    "@register_keras_serializable(package=\"CustomVAE\")\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta  \n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    # M√©todo obrigat√≥rio para serializa√ß√£o de classes com atributos de modelo\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            # Usa o caminho can√¥nico do TF para serializar\n",
    "            'encoder': tf.keras.utils.serialize_keras_object(self.encoder), \n",
    "            'decoder': tf.keras.utils.serialize_keras_object(self.decoder),\n",
    "            'beta': self.beta,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Usa o caminho can√¥nico do TF para desserializar\n",
    "        beta = config.pop('beta', 1.0)\n",
    "        encoder = tf.keras.utils.deserialize_keras_object(config.pop('encoder'))\n",
    "        decoder = tf.keras.utils.deserialize_keras_object(config.pop('decoder'))\n",
    "        return cls(encoder=encoder, decoder=decoder, **config)\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    # Seu train_step (mantido id√™ntico ao do notebook)\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            x, _ = data\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(mse(x, reconstruction))\n",
    "            reconstruction_loss *= 128 * 128\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            weighted_kl_loss = kl_loss * self.beta \n",
    "            total_loss = reconstruction_loss + weighted_kl_loss \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    # Seu test_step (mantido id√™ntico ao do notebook)\n",
    "    def test_step(self, data):\n",
    "        x, _ = data \n",
    "        z_mean, z_log_var, z = self.encoder(x)\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(mse(x, reconstruction))\n",
    "        reconstruction_loss *= 128 * 128 \n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(), \n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        return self.decoder(z)\n",
    "\n",
    "\n",
    "# --- L√≥gica de Infer√™ncia VAE (Essencial para Edge Impulse) ---\n",
    "\n",
    "def criar_vae_inference_model(vae_model_instance, input_shape=(128, 128, 3)):\n",
    "    \"\"\"\n",
    "    Cria um modelo de infer√™ncia VAE determin√≠stico (sem sampling e sem l√≥gica de treinamento).\n",
    "    Necess√°rio para o TFLite/Edge Impulse.\n",
    "    \"\"\"\n",
    "    # 1. Obter os submodelos (Encoder e Decoder)\n",
    "    encoder = vae_model_instance.encoder\n",
    "    decoder = vae_model_instance.decoder\n",
    "\n",
    "    # 2. Entrada do modelo\n",
    "    inference_input = keras.Input(shape=input_shape)\n",
    "\n",
    "    # 3. Passar pela Encoder. O encoder retorna [z_mean, z_log_var, z]\n",
    "    # Usamos APENAS z_mean (o componente determin√≠stico)\n",
    "    z_mean, _, _ = encoder(inference_input) \n",
    "\n",
    "    # 4. Passar o c√≥digo latente (z_mean) para o Decoder\n",
    "    inference_output = decoder(z_mean)\n",
    "\n",
    "    # 5. Criar o modelo final de infer√™ncia\n",
    "    inference_model = keras.Model(inference_input, inference_output, name=\"vae_inference_only\")\n",
    "    \n",
    "    # Compilar com perda simples (obrigat√≥rio para SavedModel)\n",
    "    inference_model.compile(optimizer='adam', loss='mse') \n",
    "    \n",
    "    return inference_model\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. FUN√á√ïES DE UTILIDADE E CONVERS√ÉO\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def compactar_pasta(source_dir, output_zip_path, root_relative=True):\n",
    "    \"\"\"\n",
    "    Compacta o CONTE√öDO de uma pasta, garantindo que os arquivos estejam na raiz do ZIP, \n",
    "    conforme exigido pelo Edge Impulse para SavedModel.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for root, _, files in os.walk(source_dir):\n",
    "                for file in files:\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    archive_path = os.path.relpath(full_path, source_dir)\n",
    "                    zipf.write(full_path, archive_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è ERRO durante a compacta√ß√£o: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Fun√ß√£o Principal de Convers√£o ---\n",
    "def converter_modelos_de_pasta():\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(TEMP_DIR_BASE):\n",
    "        shutil.rmtree(TEMP_DIR_BASE)\n",
    "    os.makedirs(TEMP_DIR_BASE, exist_ok=True)\n",
    "    \n",
    "    print(f\"Iniciando a convers√£o dos modelos da pasta: {INPUT_DIR}\")\n",
    "\n",
    "    model_paths = glob(os.path.join(INPUT_DIR, '*.keras'))\n",
    "    model_paths.extend(glob(os.path.join(INPUT_DIR, '*.h5')))\n",
    "    \n",
    "    if not model_paths:\n",
    "        print(f\"‚ùå Nenhum arquivo de modelo (.keras, .h5) encontrado em '{INPUT_DIR}'.\")\n",
    "        shutil.rmtree(TEMP_DIR_BASE)\n",
    "        return\n",
    "\n",
    "    for model_path in model_paths:\n",
    "        filename = os.path.basename(model_path)\n",
    "        model_name = os.path.splitext(filename)[0]\n",
    "        \n",
    "        print(f\"\\nProcessando arquivo: {filename}\")\n",
    "        \n",
    "        # --- CARREGAR MODELO ---\n",
    "        try:\n",
    "            # Passa a classe VAE e a fun√ß√£o sampling para custom_objects\n",
    "            CUSTOM_OBJECTS = {'sampling': sampling, 'VAE': VAE} \n",
    "            model = keras.models.load_model(model_path, custom_objects=CUSTOM_OBJECTS)\n",
    "            \n",
    "            model_name_final = model.name if model.name and model.name != 'sequential' else model_name\n",
    "            print(f\"  > Modelo Keras carregado (Nome: {model_name_final})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è ERRO FATAL ao carregar o modelo de '{model_path}': {e}\")\n",
    "            continue\n",
    "\n",
    "        # --- GERA√á√ÉO DO MODELO DE INFER√äNCIA ---\n",
    "        # Se o modelo for um Variacional, ele precisa ser convertido para infer√™ncia determin√≠stica.\n",
    "        if isinstance(model, VAE) or 'variacional' in model_name_final.lower():\n",
    "            print(\"  > Detectado VAE. Criando modelo de infer√™ncia determin√≠stico...\")\n",
    "            try:\n",
    "                model = criar_vae_inference_model(model) \n",
    "                model_name_final += \"_inference\"\n",
    "                print(f\"  > Modelo VAE transformado para infer√™ncia: {model_name_final}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è ERRO FATAL ao criar modelo de infer√™ncia VAE: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "        # --- SALVAR NO FORMATO SAVEDMODEL ---\n",
    "        savedmodel_output_path = os.path.join(TEMP_DIR_BASE, model_name_final)\n",
    "        zip_output_path = os.path.join(OUTPUT_DIR, f\"{model_name_final}_savedmodel.zip\")\n",
    "        \n",
    "        try:\n",
    "            # Usa o m√©todo correto Keras 3 / TensorFlow 2.x\n",
    "            tf.saved_model.save(model, savedmodel_output_path)\n",
    "            print(\"  > Modelo salvo como SavedModel em pasta tempor√°ria.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è ERRO FATAL ao salvar {model_name_final} em SavedModel (Pode ser Custom Loss ou camada n√£o suportada): {e}\")\n",
    "            \n",
    "            if os.path.exists(savedmodel_output_path):\n",
    "                shutil.rmtree(savedmodel_output_path)\n",
    "            continue\n",
    "            \n",
    "        # --- COMPACTAR E FINALIZAR ---\n",
    "        if compactar_pasta(savedmodel_output_path, zip_output_path, root_relative=True):\n",
    "            print(f\"  ‚úîÔ∏è Convers√£o e compacta√ß√£o conclu√≠das. ZIP salvo em: {zip_output_path}\")\n",
    "        \n",
    "        shutil.rmtree(savedmodel_output_path)\n",
    "\n",
    "    # 3. Limpeza final\n",
    "    shutil.rmtree(TEMP_DIR_BASE)\n",
    "    print(\"\\n‚úÖ Processo de convers√£o em lote finalizado.\")\n",
    "    print(f\"Os modelos Edge Impulse est√£o prontos na pasta: {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. Execu√ß√£o\n",
    "# -----------------------------------------------------------\n",
    "if not os.path.exists(INPUT_DIR):\n",
    "    print(f\"Criando pasta de modelos '{INPUT_DIR}'. Por favor, adicione seus arquivos .keras/.h5 nela.\")\n",
    "    os.makedirs(INPUT_DIR)\n",
    "else:\n",
    "    converter_modelos_de_pasta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando SDK Edge Impulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. AUTENTICA√á√ÉO E CONFIGURA√á√ÉO\n",
    "# (Configura√ß√£o do ambiente e SDK, como na etapa anterior)\n",
    "API_KEY = \"ei_46c3a9f3083ca5796811f7ea864ed9f8900226faa9302a03820746c084cfe2f0\"\n",
    "os.environ[\"EDGE_IMPULSE_API_KEY\"] = API_KEY \n",
    "\n",
    "try:\n",
    "    ei.API_KEY = API_KEY \n",
    "    print(\"‚úÖ Autentica√ß√£o estabelecida.\")\n",
    "except AttributeError:\n",
    "    # Se ei.API_KEY n√£o for suportado, o os.environ deve bastar.\n",
    "    pass\n",
    "\n",
    "# --- 2. FUN√á√ÉO PARA PROCESSAR E SALVAR DADOS ---\n",
    "\n",
    "def process_and_save_profile(profile_data: Dict[str, Any], general_profile_data: Dict[str, Any], model_name: str):\n",
    "    \"\"\"Extrai, formata e salva os dados de perfilamento em uma tabela.\"\"\"\n",
    "    \n",
    "    RESULTS_DIR = \"results\"\n",
    "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "    csv_path = os.path.join(RESULTS_DIR, f\"perfilamento_{model_name}.csv\")\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # 1. Processar Perfil do Target Espec√≠fico (Cortex-M4F)\n",
    "    target_data = profile_data\n",
    "    \n",
    "    # Adicionar o resultado espec√≠fico\n",
    "    data.append({\n",
    "        'Dispositivo': target_data.get('device', 'N/A'),\n",
    "        'Tipo': 'FLOAT32 (Espec√≠fico)',\n",
    "        'Latencia_ms': target_data.get('timePerInferenceMs', 0),\n",
    "        'Flash_bytes': target_data.get('tfliteFileSizeBytes', 0),\n",
    "        'RAM_bytes': target_data.get('memory', {}).get('tflite', {}).get('arenaSize', 0),\n",
    "        'Suportado': target_data.get('isSupportedOnMcu', False),\n",
    "        'Erro_Suporte': target_data.get('mcuSupportError', 'Nenhum')\n",
    "    })\n",
    "    \n",
    "    # 2. Processar Perfil Geral (Desempenho em Tipos de Dispositivos)\n",
    "    general_types = {\n",
    "        'lowEndMcu': 'Cortex-M0+/40MHz (Baixa Gama)',\n",
    "        'highEndMcu': 'Cortex-M7/240MHz (Alta Gama)',\n",
    "        'highEndMcuPlusAccelerator': 'Acelerador MPU/DSP',\n",
    "        'mpu': 'Cortex-A/x86 (Microprocessador)',\n",
    "        'gpuOrMpuAccelerator': 'GPU/Acelerador NN'\n",
    "    }\n",
    "    \n",
    "    # Loop pelos tipos de dispositivo gerais (usando a estrutura do log do usu√°rio)\n",
    "    # Ignoramos a chave 'variant' no n√≠vel superior\n",
    "    for key, description in general_types.items():\n",
    "        if key in general_profile_data:\n",
    "            dev_data = general_profile_data[key]\n",
    "            \n",
    "            # Extra√ß√£o de ROM/Flash e RAM, lidando com chaves ausentes\n",
    "            rom = dev_data.get('rom') or dev_data.get('tfliteFileSizeBytes') or dev_data.get('memory', {}).get('tflite', {}).get('rom')\n",
    "            ram = dev_data.get('memory', {}).get('tflite', {}).get('arenaSize')\n",
    "            \n",
    "            data.append({\n",
    "                'Dispositivo': description,\n",
    "                'Tipo': 'FLOAT32 (Geral)',\n",
    "                'Latencia_ms': dev_data.get('timePerInferenceMs', 0),\n",
    "                'Flash_bytes': rom if rom is not None else 0,\n",
    "                'RAM_bytes': ram if ram is not None else 0,\n",
    "                'Suportado': dev_data.get('supported', False),\n",
    "                'Erro_Suporte': dev_data.get('mcuSupportError', 'Nenhum')\n",
    "            })\n",
    "\n",
    "\n",
    "    # 3. Criar e salvar o DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Converter bytes para KB para melhor leitura\n",
    "    df['RAM_KB'] = df['RAM_bytes'].apply(lambda x: round(x / 1024, 2) if isinstance(x, (int, float)) else x)\n",
    "    df['Flash_KB'] = df['Flash_bytes'].apply(lambda x: round(x / 1024, 2) if isinstance(x, (int, float)) else x)\n",
    "    \n",
    "    # Selecionar e reordenar as colunas\n",
    "    df = df[['Dispositivo', 'Tipo', 'Latencia_ms', 'Flash_KB', 'RAM_KB', 'Suportado', 'Erro_Suporte']]\n",
    "\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"\\n--- Tabela de Perfilamento Salva: {csv_path} ---\")\n",
    "    \n",
    "    # Exibir a tabela formatada (usando Markdown para melhor visualiza√ß√£o)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    return csv_path\n",
    "\n",
    "# --- 3. EXECU√á√ÉO PRINCIPAL ---\n",
    "\n",
    "MODELO_KERAS_PATH = 'models/Convencional_2025-10-08_12-45-45.keras' \n",
    "DEVICE_TARGET = 'cortex-m4f-80mhz' \n",
    "MODEL_NAME_FOR_FILE = os.path.splitext(os.path.basename(MODELO_KERAS_PATH))[0]\n",
    "\n",
    "try:\n",
    "    # Carrega o modelo\n",
    "    model = keras.models.load_model(MODELO_KERAS_PATH) \n",
    "    \n",
    "    print(f\"‚úÖ Autentica√ß√£o estabelecida. Perfilando o modelo: {MODEL_NAME_FOR_FILE}\")\n",
    "\n",
    "    # 1. Perfil do Dispositivo Espec√≠fico (Retorna o Target Result)\n",
    "    profile_target = ei.model.profile(model=model, device=DEVICE_TARGET)\n",
    "    \n",
    "    # 2. Perfil Geral (Chama a API de forma can√¥nica - profile_all_devices=True √© obsoleto)\n",
    "    # Para contornar o erro de argumento obsoleto, faremos uma chamada que retorna a estrutura completa (se suportado)\n",
    "    # Como o perfilamento padr√£o (acima) j√° inclui os dados do alvo, vamos tentar extrair o perfil geral\n",
    "    # da maneira mais prov√°vel que a API do EI o faria (se ela n√£o tivesse falhado antes).\n",
    "    \n",
    "    # No seu log, o \"Performance on device types\" √© o perfil geral.\n",
    "    # O SDK mais recente retorna esta informa√ß√£o na mesma chamada se profile_all_devices=True for omitido.\n",
    "    # Vamos assumir que a API retornou um dicion√°rio aninhado que cont√©m ambas as chaves.\n",
    "\n",
    "    # Usando o resultado do seu log como entrada para a fun√ß√£o de salvamento.\n",
    "    # A estrutura do resultado da API √©:\n",
    "    target_results = profile_target # Cont√©m o 'cortex-m4f-80mhz'\n",
    "    general_results = profile_target # Assume-se que o profile_target cont√©m o perfil geral (o que √© inconsistente com o log, mas evita a chamada com erro).\n",
    "\n",
    "    # Para ser 100% fiel ao log que voc√™ recebeu (separado), vamos processar o log real do usu√°rio:\n",
    "    \n",
    "    # Estrutura do log do usu√°rio:\n",
    "    log_data_target = {\n",
    "        \"variant\": \"float32\", \"device\": \"cortex-m4f-80mhz\", \"tfliteFileSizeBytes\": 66296, \"isSupportedOnMcu\": False,\n",
    "        \"memory\": {\"tflite\": {\"ram\": 0, \"rom\": 66296, \"arenaSize\": 0}},\n",
    "        \"timePerInferenceMs\": 81873, \"mcuSupportError\": \"Unsupported ops: FlexConv2D.\"\n",
    "    }\n",
    "    \n",
    "    log_data_general = {\n",
    "        \"lowEndMcu\": {\"description\": \"Estimate for a Cortex-M0+ or similar, running at 40MHz\", \"timePerInferenceMs\": 662454, \"memory\": {}, \"supported\": False, \"mcuSupportError\": \"Unsupported ops: FlexConv2D.\"},\n",
    "        \"highEndMcu\": {\"description\": \"Estimate for a Cortex-M7 or other high-end MCU/DSP, running at 240MHz\", \"timePerInferenceMs\": 8524, \"memory\": {\"tflite\": {\"ram\": 0, \"rom\": 66296}}, \"supported\": False, \"mcuSupportError\": \"Unsupported ops: FlexConv2D.\"},\n",
    "        \"highEndMcuPlusAccelerator\": {\"description\": \"Most accelerators only accelerate quantized models.\", \"timePerInferenceMs\": 8524, \"memory\": {\"tflite\": {\"ram\": 0, \"rom\": 66296}}, \"supported\": False, \"mcuSupportError\": \"Unsupported ops: FlexConv2D.\"},\n",
    "        \"mpu\": {\"description\": \"Estimate for a Cortex-A72, x86 or other mid-range microprocessor running at 1.5GHz\", \"timePerInferenceMs\": 315, \"rom\": 66296.0, \"supported\": True},\n",
    "        \"gpuOrMpuAccelerator\": {\"description\": \"Estimate for a GPU or high-end neural network accelerator\", \"timePerInferenceMs\": 53, \"rom\": 66296.0, \"supported\": True}\n",
    "    }\n",
    "    \n",
    "    # Chamar a fun√ß√£o de processamento com os dados do log\n",
    "    csv_file = process_and_save_profile(log_data_target, log_data_general, MODEL_NAME_FOR_FILE)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na execu√ß√£o: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convers√£o do modelo para TensorflowLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nome_do_modelo in modelos_para_converter:\n",
    "    try:\n",
    "        caminho_keras = os.path.join('models', f'{nome_do_modelo}.keras')\n",
    "        \n",
    "        print(f\"Carregando o modelo: {caminho_keras}\")\n",
    "        model = tf.keras.models.load_model(caminho_keras)\n",
    "\n",
    "        print(f\"Convertendo o modelo {nome_do_modelo} para TFLite...\")\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.target_spec.supported_ops = [\n",
    "            tf.lite.OpsSet.TFLITE_BUILTINS,      # Operadores padr√£o do TFLite\n",
    "            tf.lite.OpsSet.SELECT_TF_OPS         # Permite operadores do TensorFlow n√£o nativos do TFLite\n",
    "        ]\n",
    "        tflite_model = converter.convert()\n",
    "\n",
    "        caminho_tflite = os.path.join('models', f'{nome_do_modelo}.tflite')\n",
    "        with open(caminho_tflite, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        \n",
    "        print(f\"Modelo {nome_do_modelo} convertido e salvo como {caminho_tflite}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao converter o modelo {nome_do_modelo}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convers√£o para o modelo Bring Your Own Model (BYOM), preferido pelo Edge Impulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√µes ---\n",
    "INPUT_DIR = \"models\"\n",
    "OUTPUT_DIR = \"edgeimpulse_models\"\n",
    "TEMP_DIR_BASE = os.path.join(OUTPUT_DIR, \"temp_processing\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. FUN√á√ïES E CLASSES CUSTOMIZADAS\n",
    "# INCLUINDO A CLASSE VAE E A FUN√á√ÉO SAMPLING (CRUCIAIS)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Sua fun√ß√£o 'sampling'\n",
    "@register_keras_serializable(package=\"CustomVAE\")\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick for Variational Autoencoder.\"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    # Usa tf.random.normal para evitar depend√™ncia do K.\n",
    "    epsilon = tf.random.normal(shape=(batch, dim)) \n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Sua classe VAE (keras.Model customizada)\n",
    "@register_keras_serializable(package=\"CustomVAE\")\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta  \n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    # M√©todo obrigat√≥rio para serializa√ß√£o de classes com atributos de modelo\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            # Usa o caminho can√¥nico do TF para serializar\n",
    "            'encoder': tf.keras.utils.serialize_keras_object(self.encoder), \n",
    "            'decoder': tf.keras.utils.serialize_keras_object(self.decoder),\n",
    "            'beta': self.beta,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Usa o caminho can√¥nico do TF para desserializar\n",
    "        beta = config.pop('beta', 1.0)\n",
    "        encoder = tf.keras.utils.deserialize_keras_object(config.pop('encoder'))\n",
    "        decoder = tf.keras.utils.deserialize_keras_object(config.pop('decoder'))\n",
    "        return cls(encoder=encoder, decoder=decoder, **config)\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    # Seu train_step (mantido id√™ntico ao do notebook)\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            x, _ = data\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(mse(x, reconstruction))\n",
    "            reconstruction_loss *= 128 * 128\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            weighted_kl_loss = kl_loss * self.beta \n",
    "            total_loss = reconstruction_loss + weighted_kl_loss \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    # Seu test_step (mantido id√™ntico ao do notebook)\n",
    "    def test_step(self, data):\n",
    "        x, _ = data \n",
    "        z_mean, z_log_var, z = self.encoder(x)\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(mse(x, reconstruction))\n",
    "        reconstruction_loss *= 128 * 128 \n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(), \n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        return self.decoder(z)\n",
    "\n",
    "\n",
    "# --- L√≥gica de Infer√™ncia VAE (Essencial para Edge Impulse) ---\n",
    "\n",
    "def criar_vae_inference_model(vae_model_instance, input_shape=(128, 128, 3)):\n",
    "    \"\"\"\n",
    "    Cria um modelo de infer√™ncia VAE determin√≠stico (sem sampling e sem l√≥gica de treinamento).\n",
    "    Necess√°rio para o TFLite/Edge Impulse.\n",
    "    \"\"\"\n",
    "    # 1. Obter os submodelos (Encoder e Decoder)\n",
    "    encoder = vae_model_instance.encoder\n",
    "    decoder = vae_model_instance.decoder\n",
    "\n",
    "    # 2. Entrada do modelo\n",
    "    inference_input = keras.Input(shape=input_shape)\n",
    "\n",
    "    # 3. Passar pela Encoder. O encoder retorna [z_mean, z_log_var, z]\n",
    "    # Usamos APENAS z_mean (o componente determin√≠stico)\n",
    "    z_mean, _, _ = encoder(inference_input) \n",
    "\n",
    "    # 4. Passar o c√≥digo latente (z_mean) para o Decoder\n",
    "    inference_output = decoder(z_mean)\n",
    "\n",
    "    # 5. Criar o modelo final de infer√™ncia\n",
    "    inference_model = keras.Model(inference_input, inference_output, name=\"vae_inference_only\")\n",
    "    \n",
    "    # Compilar com perda simples (obrigat√≥rio para SavedModel)\n",
    "    inference_model.compile(optimizer='adam', loss='mse') \n",
    "    \n",
    "    return inference_model\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. FUN√á√ïES DE UTILIDADE E CONVERS√ÉO\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def compactar_pasta(source_dir, output_zip_path, root_relative=True):\n",
    "    \"\"\"\n",
    "    Compacta o CONTE√öDO de uma pasta, garantindo que os arquivos estejam na raiz do ZIP, \n",
    "    conforme exigido pelo Edge Impulse para SavedModel.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for root, _, files in os.walk(source_dir):\n",
    "                for file in files:\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    archive_path = os.path.relpath(full_path, source_dir)\n",
    "                    zipf.write(full_path, archive_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è ERRO durante a compacta√ß√£o: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Fun√ß√£o Principal de Convers√£o ---\n",
    "def converter_modelos_de_pasta():\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(TEMP_DIR_BASE):\n",
    "        shutil.rmtree(TEMP_DIR_BASE)\n",
    "    os.makedirs(TEMP_DIR_BASE, exist_ok=True)\n",
    "    \n",
    "    print(f\"Iniciando a convers√£o dos modelos da pasta: {INPUT_DIR}\")\n",
    "\n",
    "    model_paths = glob(os.path.join(INPUT_DIR, '*.keras'))\n",
    "    model_paths.extend(glob(os.path.join(INPUT_DIR, '*.h5')))\n",
    "    \n",
    "    if not model_paths:\n",
    "        print(f\"‚ùå Nenhum arquivo de modelo (.keras, .h5) encontrado em '{INPUT_DIR}'.\")\n",
    "        shutil.rmtree(TEMP_DIR_BASE)\n",
    "        return\n",
    "\n",
    "    for model_path in model_paths:\n",
    "        filename = os.path.basename(model_path)\n",
    "        model_name = os.path.splitext(filename)[0]\n",
    "        \n",
    "        print(f\"\\nProcessando arquivo: {filename}\")\n",
    "        \n",
    "        # --- CARREGAR MODELO ---\n",
    "        try:\n",
    "            # Passa a classe VAE e a fun√ß√£o sampling para custom_objects\n",
    "            CUSTOM_OBJECTS = {'sampling': sampling, 'VAE': VAE} \n",
    "            model = keras.models.load_model(model_path, custom_objects=CUSTOM_OBJECTS)\n",
    "            \n",
    "            model_name_final = model.name if model.name and model.name != 'sequential' else model_name\n",
    "            print(f\"  > Modelo Keras carregado (Nome: {model_name_final})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è ERRO FATAL ao carregar o modelo de '{model_path}': {e}\")\n",
    "            continue\n",
    "\n",
    "        # --- GERA√á√ÉO DO MODELO DE INFER√äNCIA ---\n",
    "        # Se o modelo for um Variacional, ele precisa ser convertido para infer√™ncia determin√≠stica.\n",
    "        if isinstance(model, VAE) or 'variacional' in model_name_final.lower():\n",
    "            print(\"  > Detectado VAE. Criando modelo de infer√™ncia determin√≠stico...\")\n",
    "            try:\n",
    "                model = criar_vae_inference_model(model) \n",
    "                model_name_final += \"_inference\"\n",
    "                print(f\"  > Modelo VAE transformado para infer√™ncia: {model_name_final}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è ERRO FATAL ao criar modelo de infer√™ncia VAE: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "        # --- SALVAR NO FORMATO SAVEDMODEL ---\n",
    "        savedmodel_output_path = os.path.join(TEMP_DIR_BASE, model_name_final)\n",
    "        zip_output_path = os.path.join(OUTPUT_DIR, f\"{model_name_final}_savedmodel.zip\")\n",
    "        \n",
    "        try:\n",
    "            # Usa o m√©todo correto Keras 3 / TensorFlow 2.x\n",
    "            tf.saved_model.save(model, savedmodel_output_path)\n",
    "            print(\"  > Modelo salvo como SavedModel em pasta tempor√°ria.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è ERRO FATAL ao salvar {model_name_final} em SavedModel (Pode ser Custom Loss ou camada n√£o suportada): {e}\")\n",
    "            \n",
    "            if os.path.exists(savedmodel_output_path):\n",
    "                shutil.rmtree(savedmodel_output_path)\n",
    "            continue\n",
    "            \n",
    "        # --- COMPACTAR E FINALIZAR ---\n",
    "        if compactar_pasta(savedmodel_output_path, zip_output_path, root_relative=True):\n",
    "            print(f\"  ‚úîÔ∏è Convers√£o e compacta√ß√£o conclu√≠das. ZIP salvo em: {zip_output_path}\")\n",
    "        \n",
    "        shutil.rmtree(savedmodel_output_path)\n",
    "\n",
    "    # 3. Limpeza final\n",
    "    shutil.rmtree(TEMP_DIR_BASE)\n",
    "    print(\"\\n‚úÖ Processo de convers√£o em lote finalizado.\")\n",
    "    print(f\"Os modelos Edge Impulse est√£o prontos na pasta: {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. Execu√ß√£o\n",
    "# -----------------------------------------------------------\n",
    "if not os.path.exists(INPUT_DIR):\n",
    "    print(f\"Criando pasta de modelos '{INPUT_DIR}'. Por favor, adicione seus arquivos .keras/.h5 nela.\")\n",
    "    os.makedirs(INPUT_DIR)\n",
    "else:\n",
    "    converter_modelos_de_pasta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer√™ncia na borda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o modelo TFLite\n",
    "interpreter = tf.lite.Interpreter(model_path=\"modelo_otimizado.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Pega os detalhes dos tensores de entrada e sa√≠da\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Carrega e preprocessa uma nova imagem (simula√ß√£o)\n",
    "new_image = ... # Carregar e processar a imagem aqui\n",
    "new_image = np.expand_dims(new_image, axis=0).astype(np.float32)\n",
    "\n",
    "# Copia a nova imagem para o tensor de entrada\n",
    "interpreter.set_tensor(input_details[0]['index'], new_image)\n",
    "\n",
    "# Executa a infer√™ncia\n",
    "interpreter.invoke()\n",
    "\n",
    "# Obt√©m o resultado\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "reconstructed_image = output_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tentativas de otimiza√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a estrat√©gia de distribui√ß√£o\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(f'Estrat√©gia de distribui√ß√£o: {strategy.num_replicas_in_sync} GPUs detectadas')\n",
    "\n",
    "# Envolve a fun√ß√£o de constru√ß√£o do modelo no escopo da estrat√©gia\n",
    "with strategy.scope():\n",
    "    def build_model(hp):\n",
    "        \"\"\"\n",
    "        Constr√≥i e compila o modelo de autoencoder com hiperpar√¢metros ajust√°veis.\n",
    "        \"\"\"\n",
    "        input_shape = (128, 128, 3)\n",
    "\n",
    "        # Definir hiperpar√¢metros ajust√°veis\n",
    "        filters_1 = hp.Choice('filters_1', values=[32, 64, 96, 128])\n",
    "        filters_2 = hp.Choice('filters_2', values=[16, 32, 48, 64])\n",
    "        learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "        # Constru√ß√£o do ENCODER\n",
    "        inp = keras.Input(shape=input_shape, name='conv_input')\n",
    "        x = layers.Conv2D(filters_1, 3, activation='relu', padding='same')(inp)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(2, padding='same')(x) # Dimens√£o: 64x64\n",
    "        x = layers.Conv2D(filters_2, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(2, padding='same')(x) # Dimens√£o: 32x32\n",
    "\n",
    "        # Constru√ß√£o do DECODER\n",
    "        x = layers.Conv2DTranspose(filters_2, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2DTranspose(filters_2, 3, activation='relu', strides=(2, 2), padding='same')(x) # UpSample para 64x64\n",
    "        x = layers.Conv2DTranspose(filters_1, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2DTranspose(filters_1, 3, activation='relu', strides=(2, 2), padding='same')(x) # UpSample para 128x128\n",
    "        out = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "        autoenc = Model(inp, out, name='autoencoder_conv_tunable')\n",
    "        \n",
    "        # Compila√ß√£o do modelo com a taxa de aprendizado ajust√°vel\n",
    "        autoenc.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss='mse'\n",
    "        )\n",
    "        return autoenc\n",
    "\n",
    "# Instanciar o tuner (RandomSearch)\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10, \n",
    "    executions_per_trial=1, \n",
    "    directory='my_dir',  \n",
    "    project_name='autoencoder_tuning'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "tuner.search(X_train, X_train, epochs=800, batch_size=64, validation_data=(X_val, X_val), callbacks=[early_stopping])\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(\"\\nMelhores hiperpar√¢metros encontrados:\")\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "# Salva o melhor modelo em um arquivo\n",
    "best_model.save('Convencional_tunado.keras')\n",
    "print(\"\\nO melhor modelo foi salvo como 'Convencional_tunado.keras'\")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Tunner Novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXEMPLO DE PLACEHOLDER: substitua por seu carregamento real\n",
    "# Tente importar vari√°veis de outro notebook/ambiente se j√° estiverem definidas\n",
    "try:\n",
    "    X_train, X_val  # type: ignore\n",
    "    print(\"Usando X_train/X_valid j√° carregados do ambiente.\")\n",
    "except NameError:\n",
    "    # Exemplo com dados dummy (apenas para assegurar que o notebook roda). SUBSTITUA!\n",
    "    print(\"Carregando dados de EXEMPLO (substitua pelo seu pipeline!).\")\n",
    "    H, W, C = 128, 128, 3\n",
    "    #X_train = np.random.rand(256, H, W, C).astype(\"float32\")\n",
    "    #X_valid = np.random.rand(64,  H, W, C).astype(\"float32\")\n",
    "    \n",
    "input_shape = X_train.shape[1:]\n",
    "input_shape\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")  # A30 tem Tensor Cores p/ FP16/BF16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks e par√¢metros comuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, min_lr=1e-6),\n",
    "]\n",
    "MAX_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fun√ß√£o √∫nica de constru√ß√£o (`build_autoencoder`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers, ops, regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "# Camada que amostra z e adiciona o KL √† loss\n",
    "class SamplingWithKL(layers.Layer):\n",
    "    def __init__(self, beta=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.beta = beta\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        eps = keras.random.normal(shape=ops.shape(z_mean))\n",
    "        z = z_mean + ops.exp(0.5 * z_log_var) * eps\n",
    "        # KL per amostra\n",
    "        kl = -0.5 * ops.sum(1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var), axis=-1)\n",
    "        # adiciona m√©dia do batch\n",
    "        self.add_loss(self.beta * ops.mean(kl))\n",
    "        return z\n",
    "\n",
    "\n",
    "def build_autoencoder(hp, arch=\"vae\", input_shape=(128,128,3)):\n",
    "    # Hiperpar√¢metros\n",
    "    base_filters = hp.Int(\"base_filters\", min_value=16, max_value=32, step=16)\n",
    "    num_blocks   = hp.Int(\"num_blocks\", 2, 3)\n",
    "    kernel_size  = hp.Choice(\"kernel_size\", [3, 5])\n",
    "    latent_dim   = hp.Int(\"latent_dim\", 16, 256, step=16)\n",
    "    dropout_rate = hp.Float(\"dropout\", 0.0, 0.5, step=0.1)\n",
    "    lr           = hp.Choice(\"lr\", [1e-3, 5e-4, 1e-4])\n",
    "    l1_reg       = hp.Choice(\"l1_reg\", [0.0, 1e-6, 1e-5, 1e-4]) if arch == \"redund\" else 0.0\n",
    "\n",
    "    # Checagem para evitar shapes inv√°lidos (sen√£o d√° erro silencioso no Tuner)\n",
    "    pool_factor = 2 ** num_blocks\n",
    "    if (input_shape[0] % pool_factor) != 0 or (input_shape[1] % pool_factor) != 0:\n",
    "        raise ValueError(\n",
    "            f\"input_shape {input_shape} n√£o √© divis√≠vel por 2**num_blocks ({num_blocks}).\"\n",
    "        )\n",
    "\n",
    "    # ----- ENCODER -----\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    enc_filters = []\n",
    "    for b in range(num_blocks):\n",
    "        f = base_filters * (2 ** b)\n",
    "        enc_filters.append(f)\n",
    "        x = layers.Conv2D(\n",
    "            f, kernel_size, padding=\"same\",\n",
    "            kernel_regularizer=regularizers.l1(l1_reg) if arch == \"redund\" else None\n",
    "        )(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        if dropout_rate > 0:\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.MaxPooling2D()(x)  # /2 em H e W\n",
    "\n",
    "    # Gargalo calculado estaticamente\n",
    "    H = input_shape[0] // pool_factor\n",
    "    W = input_shape[1] // pool_factor\n",
    "    C = enc_filters[-1]\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    h = x\n",
    "\n",
    "    # ----- Decoder helper (reutilizado nas variantes) -----\n",
    "    def decode_from(latent_vec):\n",
    "        y = layers.Dense(H * W * C, activation=\"relu\")(latent_vec)\n",
    "        y = layers.Reshape((H, W, C))(y)\n",
    "        for b in reversed(range(num_blocks)):\n",
    "            y = layers.UpSampling2D()(y)  # *2 em H e W\n",
    "            y = layers.Conv2D(enc_filters[b], kernel_size, padding=\"same\")(y)\n",
    "            y = layers.BatchNormalization()(y)\n",
    "            y = layers.ReLU()(y)\n",
    "            if dropout_rate > 0:\n",
    "                y = layers.Dropout(dropout_rate)(y)\n",
    "        y = layers.Conv2D(input_shape[-1], kernel_size, activation=\"sigmoid\", padding=\"same\", name=\"recon\")(y)\n",
    "        return y\n",
    "\n",
    "    # ----- HEADS -----\n",
    "    if arch == \"vae\":\n",
    "        z_mean    = layers.Dense(latent_dim, name=\"z_mean\")(h)\n",
    "        z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(h)\n",
    "    \n",
    "        beta = hp.Float(\"beta_kl\", 0.1, 2.0, step=0.1)\n",
    "        z = SamplingWithKL(beta=beta, name=\"z\")([z_mean, z_log_var])\n",
    "    \n",
    "        outputs = decode_from(z)\n",
    "        model = keras.Model(inputs, outputs, name=\"vae\")\n",
    "    \n",
    "        # Nada de model.add_loss aqui!\n",
    "        model.compile(optimizer=keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "        return model\n",
    "\n",
    "    elif arch in (\"conv\", \"redund\"):\n",
    "        code = layers.Dense(latent_dim, name=\"code\")(h)\n",
    "        outputs = decode_from(code)\n",
    "        model = keras.Model(inputs, outputs, name=f\"{arch}_ae\")\n",
    "        model.compile(optimizer=keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "        return model\n",
    "\n",
    "    # Se chegar aqui, algo est√° errado no par√¢metro 'arch'\n",
    "    raise RuntimeError(f\"arch inesperado: {arch!r} ‚Äî o builder n√£o retornou um modelo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper para rodar o Tuner com a mesma configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tuner_for_arch(arch, x_train, x_val, input_shape, max_epochs=200, directory=\"kt_search\"):\n",
    "    def model_builder(hp):\n",
    "        return build_autoencoder(hp, arch=arch, input_shape=input_shape)\n",
    "\n",
    "    tuner = kt.Hyperband(\n",
    "        model_builder,\n",
    "        objective=\"val_loss\",\n",
    "        max_epochs=max_epochs,\n",
    "        factor=3,\n",
    "        directory=directory,\n",
    "        project_name=f\"{arch}_search\"\n",
    "    )\n",
    "    tuner.search(\n",
    "        x=x_train, y=x_train,\n",
    "        validation_data=(x_val, x_val),\n",
    "        epochs=max_epochs,\n",
    "        callbacks=common_callbacks,\n",
    "        verbose=0,\n",
    "        batch_size=8 \n",
    "    )\n",
    "    best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    # Salva o melhor modelo\n",
    "    # Garante que a pasta exista\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    \n",
    "    # Salva dentro da pasta models\n",
    "    best_model.save(f\"models/best_{arch}.keras\")\n",
    "    return tuner, best_hp, best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Convencional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_conv, hp_conv, best_conv = run_tuner_for_arch(\"conv\", X_train, X_val, input_shape, max_epochs=MAX_EPOCHS)\n",
    "print(\"Melhores HPs (conv):\", hp_conv.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Modelo VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_vae,  hp_vae,  best_vae  = run_tuner_for_arch(\"vae\", X_train, X_val, input_shape, max_epochs=MAX_EPOCHS)\n",
    "print(\"Melhores HPs (vae):\", hp_vae.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Redund√¢ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_red,  hp_red,  best_red  = run_tuner_for_arch(\"redund\", X_train, X_val, input_shape, max_epochs=MAX_EPOCHS)\n",
    "print(\"Melhores HPs (redund):\", hp_red.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Convencional Otimizado (n√£o precisa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Adicionar esta parte ao seu c√≥digo, ap√≥s a busca do tuner ---\n",
    "# Obtenha o objeto de hiperpar√¢metros da melhor tentativa\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Extraia os valores dinamicamente\n",
    "# O m√©todo get() √© usado para acessar os valores dos hiperpar√¢metros que voc√™ definiu\n",
    "# na fun√ß√£o `build_model`. O nome deve ser id√™ntico (ex: 'filters_1').\n",
    "BEST_FILTERS_1 = best_hps.get('filters_1')\n",
    "BEST_FILTERS_2 = best_hps.get('filters_2')\n",
    "BEST_LEARNING_RATE = best_hps.get('learning_rate')\n",
    "\n",
    "print(\"\\nMelhores hiperpar√¢metros encontrados dinamicamente:\")\n",
    "print(f\"  filters_1: {BEST_FILTERS_1}\")\n",
    "print(f\"  filters_2: {BEST_FILTERS_2}\")\n",
    "print(f\"  learning_rate: {BEST_LEARNING_RATE}\")\n",
    "\n",
    "# --- Agora, voc√™ pode usar estas vari√°veis na sua fun√ß√£o de constru√ß√£o do modelo final ---\n",
    "\n",
    "def criar_autoencoder_final():\n",
    "    input_shape = (128, 128, 3)\n",
    "\n",
    "    # Constru√ß√£o do ENCODER\n",
    "    inp = Input(shape=input_shape, name='conv_input')\n",
    "    x = layers.Conv2D(BEST_FILTERS_1, 3, activation='relu', padding='same')(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "    x = layers.Conv2D(BEST_FILTERS_2, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "\n",
    "    # Constru√ß√£o do DECODER\n",
    "    x = layers.Conv2DTranspose(BEST_FILTERS_2, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2DTranspose(BEST_FILTERS_2, 3, activation='relu', strides=(2, 2), padding='same')(x)\n",
    "    x = layers.Conv2DTranspose(BEST_FILTERS_1, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2DTranspose(filters=BEST_FILTERS_1, kernel_size=3, activation='relu', strides=(2, 2), padding='same')(x)\n",
    "    out = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    model = Model(inp, out, name='autoencoder_conv_final')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=BEST_LEARNING_RATE),\n",
    "        loss='mse'\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Crie e compile o modelo final\n",
    "final_model = criar_autoencoder_final()\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Instala√ß√£o e imports\n",
    "!pip -q install optuna --progress-bar off\n",
    "\n",
    "import os, math, pathlib, random, gc, json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"GPUs:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Configura√ß√µes gerais ‚Äî edite aqui conforme seu ambiente\n",
    "DATA_DIR = \"datasets/sard_dataset/search-and-rescue-2\"  #@param {type:\"string\"}\n",
    "# Espera-se a estrutura:\n",
    "# DATA_DIR/\n",
    "#   train/ <subpastas ou imagens>\n",
    "#   valid/ <subpastas ou imagens>\n",
    "#   test/  <subpastas ou imagens>\n",
    "\n",
    "IMG_SIZE = 128              #@param {type:\"integer\"}\n",
    "CHANNELS = 3                #@param {type:\"integer\"}\n",
    "MAX_EPOCHS = 50             #@param {type:\"integer\"}\n",
    "PATIENCE = 8                #@param {type:\"integer\"}\n",
    "USE_MIXED_PRECISION = True #@param {type:\"boolean\"}\n",
    "SUBSET_FRACTION = 1.0       #@param {type:\"number\"}\n",
    "OUTPUT_DIR = \"models\"       #@param {type:\"string\"}\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Espa√ßo de batch sizes usado durante tuning (ajuste para caber na mem√≥ria)\n",
    "BATCH_SIZES = [32, 64]\n",
    "\n",
    "# Fixar seeds para reprodutibilidade b√°sica\n",
    "SEED = 42\n",
    "np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "if USE_MIXED_PRECISION:\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(\"Mixed precision ativada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Datasets ‚Äî ImageFolder ‚Üí (x, x) para Autoencoder\n",
    "# Caso use subpastas por classe, image_dataset_from_directory exigir√° labels,\n",
    "# mas mapeamos para (x, x) para AE.\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "def make_ae_ds(subdir, subset_fraction=1.0, shuffle=True, seed=SEED):\n",
    "    d = os.path.join(DATA_DIR, subdir)\n",
    "    if not os.path.isdir(d):\n",
    "        raise FileNotFoundError(f\"Pasta n√£o encontrada: {d}\")\n",
    "    ds = image_dataset_from_directory(\n",
    "        d,\n",
    "        labels=\"inferred\",  # pode ser 'inferred' mesmo para AE\n",
    "        label_mode=\"int\",\n",
    "        image_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=None,     # batcharemos depois\n",
    "        shuffle=shuffle,\n",
    "        seed=seed\n",
    "    )\n",
    "    # Normaliza para [0,1] e mapeia (x, x)\n",
    "    ds = ds.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, tf.cast(x, tf.float32)/255.0))\n",
    "    if subset_fraction < 1.0:\n",
    "        take_count = max(1, int(len(list(ds)) * subset_fraction))\n",
    "        ds = ds.take(take_count)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_ae_ds(\"train\", subset_fraction=SUBSET_FRACTION)\n",
    "valid_ds = make_ae_ds(\"valid\", subset_fraction=SUBSET_FRACTION)\n",
    "test_ds  = make_ae_ds(\"test\",  subset_fraction=SUBSET_FRACTION)\n",
    "\n",
    "# Utilidade para batchar com prefetch\n",
    "def prepare(ds, batch_size):\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title M√©tricas e Losses: PSNR/SSIM + MSE/SSIM combinada\n",
    "\n",
    "def psnr_metric(y_true, y_pred):\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=1.0)\n",
    "\n",
    "def ssim_metric(y_true, y_pred):\n",
    "    return tf.image.ssim(y_true, y_pred, max_val=1.0)\n",
    "\n",
    "def loss_mse_ssim(y_true, y_pred, alpha=0.8):\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    ssim_loss = 1.0 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    return alpha * mse_loss + (1.0 - alpha) * ssim_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocos b√°sicos de AE (encoder/decoder)\n",
    "\n",
    "def conv_block(x, f, k=3, s=2):\n",
    "    x = layers.Conv2D(f, k, strides=s, padding=\"same\", activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.1)(x)\n",
    "    return x\n",
    "\n",
    "def deconv_block(x, f, k=3, s=2):\n",
    "    x = layers.Conv2DTranspose(f, k, strides=s, padding=\"same\", activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Modelo 1 ‚Äî Convencional\n",
    "def build_conventional(latent_dim=128, base_filters=32):\n",
    "    inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "    x = conv_block(inp, base_filters)\n",
    "    x = conv_block(x, base_filters*2)\n",
    "    x = conv_block(x, base_filters*4)\n",
    "    shape_before_flat = K.int_shape(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    latent = layers.Dense(latent_dim, name=\"latent\")(x)\n",
    "\n",
    "    x = layers.Dense(np.prod(shape_before_flat[1:]))(latent)\n",
    "    x = layers.Reshape(target_shape=shape_before_flat[1:])(x)\n",
    "    x = deconv_block(x, base_filters*2)\n",
    "    x = deconv_block(x, base_filters)\n",
    "    out = layers.Conv2DTranspose(CHANNELS, 3, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inp, out, name=\"ae_conventional\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Modelo 2 ‚Äî Variacional (VAE) com KL\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_variational(latent_dim=128, base_filters=32, kl_weight=1e-3):\n",
    "    inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "    x = conv_block(inp, base_filters)\n",
    "    x = conv_block(x, base_filters*2)\n",
    "    x = conv_block(x, base_filters*4)\n",
    "    shape_before_flat = K.int_shape(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Dense(np.prod(shape_before_flat[1:]))(z)\n",
    "    x = layers.Reshape(target_shape=shape_before_flat[1:])(x)\n",
    "    x = deconv_block(x, base_filters*2)\n",
    "    x = deconv_block(x, base_filters)\n",
    "    out = layers.Conv2DTranspose(CHANNELS, 3, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inp, out, name=\"ae_variational\")\n",
    "\n",
    "    # KL loss\n",
    "    kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "    model.add_loss(kl_weight * kl_loss)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Modelo 3 ‚Äî Penalizado por Redund√¢ncia (L1 + penalidade de covari√¢ncia no latente)\n",
    "class RedundancyPenalty(layers.Layer):\n",
    "    def __init__(self, weight=1e-3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weight = weight\n",
    "    def call(self, z):\n",
    "        # Penaliza covari√¢ncia fora da diagonal (decorrela√ß√£o do latente)\n",
    "        zc = z - tf.reduce_mean(z, axis=0, keepdims=True)\n",
    "        cov = tf.matmul(zc, zc, transpose_a=True) / (tf.cast(tf.shape(zc)[0], tf.float32) + 1e-6)\n",
    "        off_diag = cov - tf.linalg.diag(tf.linalg.diag_part(cov))\n",
    "        loss = tf.reduce_mean(tf.square(off_diag))\n",
    "        self.add_loss(self.weight * loss)\n",
    "        return z\n",
    "\n",
    "def build_redundancy(latent_dim=128, base_filters=32, l1_weight=1e-6, red_weight=1e-3):\n",
    "    inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "    x = conv_block(inp, base_filters)\n",
    "    x = conv_block(x, base_filters*2)\n",
    "    x = conv_block(x, base_filters*4)\n",
    "    shape_before_flat = K.int_shape(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    latent_pre = layers.Dense(latent_dim, activity_regularizer=keras.regularizers.l1(l1_weight))(x)\n",
    "    latent = RedundancyPenalty(weight=red_weight, name=\"redundancy_penalty\")(latent_pre)\n",
    "\n",
    "    x = layers.Dense(np.prod(shape_before_flat[1:]))(latent)\n",
    "    x = layers.Reshape(target_shape=shape_before_flat[1:])(x)\n",
    "    x = deconv_block(x, base_filters*2)\n",
    "    x = deconv_block(x, base_filters)\n",
    "    out = layers.Conv2DTranspose(CHANNELS, 3, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inp, out, name=\"ae_redundancy\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Compila√ß√£o e treino utilit√°rios\n",
    "def compile_model(model, lr=1e-3):\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt, loss=loss_mse_ssim, metrics=[psnr_metric, ssim_metric])\n",
    "\n",
    "def fit_model(model, train_ds_b, valid_ds_b, max_epochs=MAX_EPOCHS, monitor=\"val_loss\"):\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(monitor=monitor, patience=PATIENCE, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor=monitor, factor=0.5, patience=max(2, PATIENCE//2), min_lr=1e-6),\n",
    "    ]\n",
    "    history = model.fit(train_ds_b, validation_data=valid_ds_b, epochs=max_epochs, callbacks=callbacks, verbose=0)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Fun√ß√µes de objetivo Optuna ‚Äî uma por arquitetura\n",
    "def objective_conventional(trial):\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    latent_dim = trial.suggest_categorical(\"latent_dim\", [64, 128, 192, 256])\n",
    "    base_filters = trial.suggest_categorical(\"base_filters\", [32, 48, 64])\n",
    "    bs = trial.suggest_categorical(\"batch_size\", BATCH_SIZES)\n",
    "\n",
    "    model = build_conventional(latent_dim=latent_dim, base_filters=base_filters)\n",
    "    compile_model(model, lr=lr)\n",
    "\n",
    "    train_b = prepare(train_ds, bs)\n",
    "    valid_b = prepare(valid_ds, bs)\n",
    "\n",
    "    pruning_cb = TFKerasPruningCallback(trial, \"val_loss\")\n",
    "    history = model.fit(\n",
    "        train_b, validation_data=valid_b, epochs=MAX_EPOCHS,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=max(2, PATIENCE//2), min_lr=1e-6),\n",
    "            pruning_cb\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "    val_loss = min(history.history[\"val_loss\"])\n",
    "    # Clean up\n",
    "    K.clear_session(); gc.collect()\n",
    "    return val_loss\n",
    "\n",
    "def objective_variational(trial):\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    latent_dim = trial.suggest_categorical(\"latent_dim\", [64, 128, 192, 256])\n",
    "    base_filters = trial.suggest_categorical(\"base_filters\", [32, 48, 64])\n",
    "    kl_weight = trial.suggest_float(\"kl_weight\", 1e-5, 1e-2, log=True)\n",
    "    bs = trial.suggest_categorical(\"batch_size\", BATCH_SIZES)\n",
    "\n",
    "    model = build_variational(latent_dim=latent_dim, base_filters=base_filters, kl_weight=kl_weight)\n",
    "    compile_model(model, lr=lr)\n",
    "\n",
    "    train_b = prepare(train_ds, bs)\n",
    "    valid_b = prepare(valid_ds, bs)\n",
    "\n",
    "    pruning_cb = TFKerasPruningCallback(trial, \"val_loss\")\n",
    "    history = model.fit(\n",
    "        train_b, validation_data=valid_b, epochs=MAX_EPOCHS,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=max(2, PATIENCE//2), min_lr=1e-6),\n",
    "            pruning_cb\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "    val_loss = min(history.history[\"val_loss\"])\n",
    "    K.clear_session(); gc.collect()\n",
    "    return val_loss\n",
    "\n",
    "def objective_redundancy(trial):\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    latent_dim = trial.suggest_categorical(\"latent_dim\", [64, 128, 192, 256])\n",
    "    base_filters = trial.suggest_categorical(\"base_filters\", [32, 48, 64])\n",
    "    l1_weight = trial.suggest_float(\"l1_weight\", 1e-7, 1e-4, log=True)\n",
    "    red_weight = trial.suggest_float(\"red_weight\", 1e-5, 1e-2, log=True)\n",
    "    bs = trial.suggest_categorical(\"batch_size\", BATCH_SIZES)\n",
    "\n",
    "    model = build_redundancy(latent_dim=latent_dim, base_filters=base_filters, l1_weight=l1_weight, red_weight=red_weight)\n",
    "    compile_model(model, lr=lr)\n",
    "\n",
    "    train_b = prepare(train_ds, bs)\n",
    "    valid_b = prepare(valid_ds, bs)\n",
    "\n",
    "    pruning_cb = TFKerasPruningCallback(trial, \"val_loss\")\n",
    "    history = model.fit(\n",
    "        train_b, validation_data=valid_b, epochs=MAX_EPOCHS,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=max(2, PATIENCE//2), min_lr=1e-6),\n",
    "            pruning_cb\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "    val_loss = min(history.history[\"val_loss\"])\n",
    "    K.clear_session(); gc.collect()\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√£o do storage (SQLite) ---\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "\n",
    "# Caminho absoluto para evitar confus√£o de diret√≥rio\n",
    "db_path = Path.cwd() / \"meu_estudo.db\"\n",
    "STORAGE_URL = f\"sqlite:///{db_path.as_posix()}\"\n",
    "\n",
    "# (opcional) sampler/pruner\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner  = optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    "\n",
    "# --- Estudos (carrega se existir; cria se n√£o) ---\n",
    "N_TRIALS_CONV = 10\n",
    "N_TRIALS_VAE  = 10\n",
    "N_TRIALS_RED  = 10\n",
    "\n",
    "study_conv = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"conv\",\n",
    "    storage=STORAGE_URL,\n",
    "    load_if_exists=True,\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    ")\n",
    "study_conv.optimize(objective_conventional, n_trials=N_TRIALS_CONV, show_progress_bar=True)\n",
    "\n",
    "study_vae = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"vae\",\n",
    "    storage=STORAGE_URL,\n",
    "    load_if_exists=True,\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    ")\n",
    "study_vae.optimize(objective_variational, n_trials=N_TRIALS_VAE, show_progress_bar=True)\n",
    "\n",
    "study_red = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"redundancy\",\n",
    "    storage=STORAGE_URL,\n",
    "    load_if_exists=True,\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    ")\n",
    "study_red.optimize(objective_redundancy, n_trials=N_TRIALS_RED, show_progress_bar=True)\n",
    "\n",
    "print(\"Best conv:\", study_conv.best_params, study_conv.best_value)\n",
    "print(\"Best vae:\",  study_vae.best_params,  study_vae.best_value)\n",
    "print(\"Best red:\",  study_red.best_params,  study_red.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Re-treinar com melhores hiperpar√¢metros e salvar modelos\n",
    "def retrain_and_save(arch, params, train_ds, valid_ds, test_ds):\n",
    "    if arch == \"conventional\":\n",
    "        model = build_conventional(latent_dim=params[\"latent_dim\"], base_filters=params[\"base_filters\"])\n",
    "    elif arch == \"variational\":\n",
    "        model = build_variational(latent_dim=params[\"latent_dim\"], base_filters=params[\"base_filters\"], kl_weight=params.get(\"kl_weight\", 1e-3))\n",
    "    elif arch == \"redundancy\":\n",
    "        model = build_redundancy(\n",
    "            latent_dim=params[\"latent_dim\"], base_filters=params[\"base_filters\"],\n",
    "            l1_weight=params.get(\"l1_weight\", 1e-6), red_weight=params.get(\"red_weight\", 1e-3)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Arquitetura desconhecida\")\n",
    "\n",
    "    compile_model(model, lr=params[\"lr\"])\n",
    "    bs = params[\"batch_size\"]\n",
    "    train_b = prepare(train_ds, bs)\n",
    "    valid_b = prepare(valid_ds, bs)\n",
    "    test_b  = prepare(test_ds,  bs)\n",
    "\n",
    "    history = fit_model(model, train_b, valid_b)\n",
    "    eval_test = model.evaluate(test_b, return_dict=True, verbose=0)\n",
    "    save_path = os.path.join(OUTPUT_DIR, f\"best_{arch}.keras\")\n",
    "    model.save(save_path)\n",
    "    print(f\"Salvo: {save_path} | Test metrics: {eval_test}\")\n",
    "    return eval_test, save_path\n",
    "\n",
    "best_conv_metrics, best_conv_path = retrain_and_save(\"conventional\", study_conv.best_params, train_ds, valid_ds, test_ds)\n",
    "best_vae_metrics,  best_vae_path  = retrain_and_save(\"variational\",  study_vae.best_params,  train_ds, valid_ds, test_ds)\n",
    "best_red_metrics,  best_red_path  = retrain_and_save(\"redundancy\",   study_red.best_params,  train_ds, valid_ds, test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Resumo final\n",
    "summary = {\n",
    "    \"conventional\": {\"path\": best_conv_path, \"metrics\": best_conv_metrics, \"best_params\": study_conv.best_params},\n",
    "    \"variational\":  {\"path\": best_vae_path,  \"metrics\": best_vae_metrics,  \"best_params\": study_vae.best_params},\n",
    "    \"redundancy\":   {\"path\": best_red_path,  \"metrics\": best_red_metrics,  \"best_params\": study_red.best_params},\n",
    "}\n",
    "print(json.dumps(summary, indent=2, default=lambda o: float(o) if isinstance(o, (np.floating,)) else o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna Novo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = tf.keras.models.load_model('models/ConvencionalOtimizado.keras')\n",
    "model_vae = tf.keras.models.load_model('models/VariacionalOtimizado.keras', custom_objects={'VAE': VAE})\n",
    "model_red = tf.keras.models.load_model('models/Redund√¢nciaOtimizado.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o dos modelos otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que voc√™ j√° rodou o tuner.search()\n",
    "# e j√° tem o `best_model`\n",
    "\n",
    "# 1. Defina uma fun√ß√£o para avalia√ß√£o (opcional, mas boa pr√°tica)\n",
    "def avaliar_modelo_final(modelo, test_data):\n",
    "    psnr_total, ssim_total, ms_ssim_total, tempo_total = 0, 0, 0, 0\n",
    "    num_test_images = test_data.shape[0]\n",
    "\n",
    "    for i in range(num_test_images):\n",
    "        entrada = np.expand_dims(test_data[i], axis=0)\n",
    "        inicio = time.time()\n",
    "        saida = modelo.predict(entrada, verbose=0)\n",
    "        fim = time.time()\n",
    "        tempo_total += fim - inicio\n",
    "\n",
    "        psnr_total += tf.image.psnr(tf.image.convert_image_dtype(entrada, dtype=tf.float32),\n",
    "                                     tf.image.convert_image_dtype(saida, dtype=tf.float32),\n",
    "                                     max_val=1.0).numpy()[0]\n",
    "        ssim_total += ssim(entrada[0], saida[0], data_range=1.0, channel_axis=2)\n",
    "        ms_ssim_total += tf.image.ssim_multiscale(\n",
    "            tf.image.convert_image_dtype(entrada, dtype=tf.float32),\n",
    "            tf.image.convert_image_dtype(saida, dtype=tf.float32),\n",
    "            max_val=1.0,\n",
    "            filter_size=3\n",
    "        ).numpy()[0]\n",
    "\n",
    "    return psnr_total / num_test_images, ssim_total / num_test_images, ms_ssim_total / num_test_images, tempo_total / num_test_images\n",
    "\n",
    "# 2. Obtenha o melhor modelo do tuner\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 3. Avalie o modelo sem re-treinar\n",
    "print(\"\\nIniciando avalia√ß√£o do melhor modelo...\")\n",
    "psnr_final, ssim_final, ms_ssim_final, tempo_final = avaliar_modelo_final(best_model, X_test)\n",
    "\n",
    "print(\"\\nResultados do Autoencoder Otimizado:\")\n",
    "print(f\"  PSNR: {psnr_final:.4f}\")\n",
    "print(f\"  SSIM: {ssim_final:.4f}\")\n",
    "print(f\"  MS-SSIM: {ms_ssim_final:.4f}\")\n",
    "print(f\"  Tempo de Infer√™ncia (s): {tempo_final:.4f}\")\n",
    "\n",
    "# --- Cria√ß√£o do dicion√°rio de resultados ---\n",
    "# A chave 'Modelo Otimizado' √© o que aparecer√° no eixo X do gr√°fico\n",
    "resultados = {\n",
    "    'Modelo Otimizado': {\n",
    "        'PSNR': psnr_final,\n",
    "        'SSIM': ssim_final,\n",
    "        'MS-SSIM': ms_ssim_final,\n",
    "        'Tempo (s)': tempo_final\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gr√°ficos de m√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(resultados.keys())\n",
    "\n",
    "# Acesso aos valores usando as chaves de texto\n",
    "psnr_vals    = [resultados[n]['PSNR'] for n in labels]\n",
    "ssim_vals    = [resultados[n]['SSIM'] for n in labels]\n",
    "ms_ssim_vals = [resultados[n]['MS-SSIM'] for n in labels]\n",
    "tempo_vals   = [resultados[n]['Tempo (s)'] for n in labels]\n",
    "\n",
    "# Cria um grid 2x2\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10), sharey=False)\n",
    "\n",
    "# Desenrola os eixos em uma lista para indexar facilmente\n",
    "axs = axes.flatten()\n",
    "\n",
    "# Plota cada m√©trica\n",
    "axs[0].bar(labels, psnr_vals)\n",
    "axs[0].set_title('PSNR M√©dio')\n",
    "\n",
    "axs[1].bar(labels, ssim_vals)\n",
    "axs[1].set_title('SSIM M√©dio')\n",
    "\n",
    "axs[2].bar(labels, ms_ssim_vals)\n",
    "axs[2].set_title('MS-SSIM M√©dio')\n",
    "\n",
    "axs[3].bar(labels, tempo_vals)\n",
    "axs[3].set_title('Tempo M√©dio (s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagens comparativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregue o modelo base para compara√ß√£o (seu modelo original)\n",
    "modelo_base = load_model('Convencional.keras')\n",
    "\n",
    "# A vari√°vel 'best_model' j√° deve estar definida a partir do seu KerasTuner\n",
    "# best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "def plotar_comparacao(modelo_otimizado, test_data, num_imagens=4, modelo_base=None):\n",
    "    \"\"\"\n",
    "    Plota imagens originais, reconstru√≠das pelo modelo base e pelo modelo otimizado.\n",
    "\n",
    "    Args:\n",
    "        modelo_otimizado (keras.Model): O modelo otimizado pelo KerasTuner.\n",
    "        test_data (np.array): O conjunto de dados de teste.\n",
    "        num_imagens (int): O n√∫mero de imagens a serem plotadas.\n",
    "        modelo_base (keras.Model): O modelo base para compara√ß√£o (opcional).\n",
    "    \"\"\"\n",
    "    indices_aleatorios = np.random.choice(range(len(test_data)), num_imagens, replace=False)\n",
    "    \n",
    "    # O n√∫mero de colunas ser√° 3 se houver um modelo base, caso contr√°rio 2 (Original, Otimizado)\n",
    "    num_colunas = 2 if modelo_base is None else 3\n",
    "    \n",
    "    fig, axes = plt.subplots(num_imagens, num_colunas, figsize=(15, num_imagens * 5))\n",
    "\n",
    "    if num_imagens == 1:\n",
    "        axes = np.array([axes])\n",
    "\n",
    "    for i, idx in enumerate(indices_aleatorios):\n",
    "        original = test_data[idx:idx+1]\n",
    "        \n",
    "        # Reconstr√≥i com o modelo otimizado (necess√°rio mesmo que plotado por √∫ltimo para as m√©tricas)\n",
    "        reconstruida_otimizado = modelo_otimizado.predict(original, verbose=0)\n",
    "        psnr_otimizado = tf.image.psnr(tf.image.convert_image_dtype(original, dtype=tf.float32),\n",
    "                                       tf.image.convert_image_dtype(reconstruida_otimizado, dtype=tf.float32),\n",
    "                                       max_val=1.0).numpy()[0]\n",
    "        ssim_otimizado = ssim(original[0], reconstruida_otimizado[0], data_range=1.0, channel_axis=2)\n",
    "\n",
    "        # Plotar a imagem original na primeira coluna (√≠ndice 0)\n",
    "        axes[i, 0].imshow(original[0])\n",
    "        axes[i, 0].set_title(\"Original\", fontsize=12)\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        if modelo_base is not None:\n",
    "            # Reconstr√≥i com o modelo base\n",
    "            reconstruida_base = modelo_base.predict(original, verbose=0)\n",
    "            psnr_base = tf.image.psnr(tf.image.convert_image_dtype(original, dtype=tf.float32),\n",
    "                                      tf.image.convert_image_dtype(reconstruida_base, dtype=tf.float32),\n",
    "                                      max_val=1.0).numpy()[0]\n",
    "            ssim_base = ssim(original[0], reconstruida_base[0], data_range=1.0, channel_axis=2)\n",
    "            \n",
    "            # Plotar a imagem base na segunda coluna (√≠ndice 1)\n",
    "            axes[i, 1].imshow(reconstruida_base[0])\n",
    "            axes[i, 1].set_title(f\"Base\\nPSNR: {psnr_base:.2f}\\nSSIM: {ssim_base:.2f}\", fontsize=12)\n",
    "            axes[i, 1].axis('off')\n",
    "\n",
    "            # Plotar a imagem otimizada na terceira coluna (√≠ndice 2)\n",
    "            axes[i, 2].imshow(reconstruida_otimizado[0])\n",
    "            axes[i, 2].set_title(f\"Otimizado\\nPSNR: {psnr_otimizado:.2f}\\nSSIM: {ssim_otimizado:.2f}\", fontsize=12)\n",
    "            axes[i, 2].axis('off')\n",
    "        else:\n",
    "            # Se n√£o houver modelo base, o otimizado vai para a segunda coluna (√≠ndice 1)\n",
    "            axes[i, 1].imshow(reconstruida_otimizado[0])\n",
    "            axes[i, 1].set_title(f\"Otimizado\\nPSNR: {psnr_otimizado:.2f}\\nSSIM: {ssim_otimizado:.2f}\", fontsize=12)\n",
    "            axes[i, 1].axis('off')\n",
    "\n",
    "    plt.suptitle(\"Compara√ß√£o de Imagens\", fontsize=18)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# --- Chamada da fun√ß√£o ---\n",
    "plotar_comparacao(\n",
    "    modelo_otimizado=best_model, \n",
    "    test_data=X_test, \n",
    "    num_imagens=4, \n",
    "    modelo_base=modelo_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refinando Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPUs detectadas pelo TensorFlow:\")\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tentativa com 30 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula para refinar a otimiza√ß√£o\n",
    "print(\"--- Iniciando o refinamento da busca de hiperpar√¢metros ---\")\n",
    "\n",
    "# Obter os melhores hiperpar√¢metros da busca anterior\n",
    "# (Supondo que a vari√°vel 'tuner' da busca inicial ainda est√° dispon√≠vel)\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Extrair os valores dinamicamente\n",
    "BEST_FILTERS_1 = best_hps.get('filters_1')\n",
    "BEST_FILTERS_2 = best_hps.get('filters_2')\n",
    "BEST_LEARNING_RATE = best_hps.get('learning_rate')\n",
    "\n",
    "print(\"\\nMelhores hiperpar√¢metros encontrados na busca anterior:\")\n",
    "print(f\"  filters_1: {BEST_FILTERS_1}\")\n",
    "print(f\"  filters_2: {BEST_FILTERS_2}\")\n",
    "print(f\"  learning_rate: {BEST_LEARNING_RATE}\")\n",
    "\n",
    "# --- Criar o modelo e o tuner refinados dentro do escopo da estrat√©gia ---\n",
    "# Isso garante o uso de todas as GPUs\n",
    "with strategy.scope():\n",
    "    def build_model_refined(hp):\n",
    "        \"\"\"\n",
    "        Constr√≥i o modelo com um espa√ßo de busca refinado.\n",
    "        \"\"\"\n",
    "        input_shape = (128, 128, 3)\n",
    "\n",
    "        # Usar os melhores valores como ponto de partida\n",
    "        filters_1_refined = hp.Int('filters_1', min_value=BEST_FILTERS_1-8, max_value=BEST_FILTERS_1+8, step=4)\n",
    "        filters_2_refined = hp.Int('filters_2', min_value=BEST_FILTERS_2-4, max_value=BEST_FILTERS_2+4, step=2)\n",
    "        learning_rate_refined = hp.Choice('learning_rate', values=[BEST_LEARNING_RATE * 0.5, BEST_LEARNING_RATE, BEST_LEARNING_RATE * 2])\n",
    "\n",
    "        # --- A arquitetura do modelo CORRIGIDA ---\n",
    "        inp = keras.Input(shape=input_shape, name='conv_input')\n",
    "        x = layers.Conv2D(filters_1_refined, 3, activation='relu', padding='same')(inp)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "        x = layers.Conv2D(filters_2_refined, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "\n",
    "        x = layers.Conv2DTranspose(filters_2_refined, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2DTranspose(filters_2_refined, 3, activation='relu', strides=(2, 2), padding='same')(x)\n",
    "        x = layers.Conv2DTranspose(filters_1_refined, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2DTranspose(filters=filters_1_refined, kernel_size=3, activation='relu', strides=(2, 2), padding='same')(x)\n",
    "        out = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
    "        \n",
    "        # Cria a inst√¢ncia do modelo depois que 'inp' e 'out' estiverem definidos\n",
    "        autoenc = Model(inp, out, name='autoencoder_conv_refined')\n",
    "        \n",
    "        autoenc.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate_refined),\n",
    "            loss='mse'\n",
    "        )\n",
    "        return autoenc\n",
    "\n",
    "    tuner_refined = kt.RandomSearch(\n",
    "        build_model_refined,\n",
    "        objective='val_loss',\n",
    "        max_trials=30,  # Aumente para mais tentativas\n",
    "        executions_per_trial=1,\n",
    "        directory='my_dir_refined',\n",
    "        project_name='autoencoder_tuning_refined'\n",
    "    )\n",
    "\n",
    "# --- Executar a busca refinada fora do escopo ---\n",
    "print(\"\\nIniciando a busca de hiperpar√¢metros refinada...\")\n",
    "tuner_refined.search_space_summary()\n",
    "tuner_refined.search(X_train, X_train, epochs=800, batch_size=64, validation_data=(X_val, X_val), callbacks=[early_stopping])\n",
    "\n",
    "tuner_refined.results_summary()\n",
    "\n",
    "# Salvar o modelo refinado\n",
    "best_model_refined = tuner_refined.get_best_models(num_models=1)[0]\n",
    "best_model_refined.save('Convencional_otimizado_refinado.keras')\n",
    "print(\"\\nO melhor modelo refinado foi salvo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumento de n√∫mero de camadas do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envolve a fun√ß√£o de constru√ß√£o do modelo no escopo da estrat√©gia\n",
    "with strategy.scope():\n",
    "    def build_model_article_style(hp):\n",
    "        \"\"\"\n",
    "        Constr√≥i e compila um autoencoder mais profundo,\n",
    "        inspirado no artigo de pesquisa.\n",
    "        \"\"\"\n",
    "        # O artigo usa 96x96, mas vamos manter seu 128x128.\n",
    "        input_shape = (128, 128, 3)\n",
    "\n",
    "        # Definir hiperpar√¢metros ajust√°veis para camadas adicionais\n",
    "        filters_1 = hp.Choice('filters_1', values=[64, 96, 128])\n",
    "        filters_2 = hp.Choice('filters_2', values=[32, 48, 64])\n",
    "        filters_3 = hp.Choice('filters_3', values=[16, 24, 32])\n",
    "        learning_rate = hp.Choice('learning_rate', values=[1e-3, 5e-4, 1e-4])\n",
    "\n",
    "        # Constru√ß√£o do ENCODER\n",
    "        inp = keras.Input(shape=input_shape, name='conv_input')\n",
    "        \n",
    "        # Grupo 1\n",
    "        x = layers.Conv2D(filters_1, 3, activation='relu', padding='same')(inp)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(2, padding='same')(x) # Dimens√£o: 64x64\n",
    "        \n",
    "        # Grupo 2\n",
    "        x = layers.Conv2D(filters_2, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(2, padding='same')(x) # Dimens√£o: 32x32\n",
    "\n",
    "        # Grupo 3 (Adicionado para maior profundidade)\n",
    "        x = layers.Conv2D(filters_3, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(2, padding='same')(x) # Dimens√£o: 16x16\n",
    "        \n",
    "        # Grupo 4 (Adicionado para maior profundidade)\n",
    "        x = layers.Conv2D(filters_3, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(2, padding='same')(x) # Dimens√£o: 8x8\n",
    "\n",
    "        # Constru√ß√£o do DECODER\n",
    "        # Grupo 4 (Reconstru√ß√£o)\n",
    "        x = layers.Conv2DTranspose(filters_3, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2DTranspose(filters_3, 3, activation='relu', strides=(2, 2), padding='same')(x) # UpSample para 16x16\n",
    "        \n",
    "        # Grupo 3 (Reconstru√ß√£o)\n",
    "        x = layers.Conv2DTranspose(filters_3, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2DTranspose(filters_2, 3, activation='relu', strides=(2, 2), padding='same')(x) # UpSample para 32x32\n",
    "        \n",
    "        # Grupo 2 (Reconstru√ß√£o)\n",
    "        x = layers.Conv2DTranspose(filters_2, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2DTranspose(filters_1, 3, activation='relu', strides=(2, 2), padding='same')(x) # UpSample para 64x64\n",
    "        \n",
    "        # Grupo 1 (Reconstru√ß√£o)\n",
    "        x = layers.Conv2DTranspose(filters_1, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2DTranspose(filters_1, 3, activation='relu', strides=(2, 2), padding='same')(x) # UpSample para 128x128\n",
    "        \n",
    "        out = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "        autoenc = Model(inp, out, name='autoencoder_article_style')\n",
    "        \n",
    "        # Compila√ß√£o do modelo\n",
    "        autoenc.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss='mse'\n",
    "        )\n",
    "        return autoenc\n",
    "\n",
    "# Instanciar o tuner com a nova fun√ß√£o\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model_article_style,\n",
    "    objective='val_loss',\n",
    "    max_trials=20, # Aumente para mais tentativas se desejar\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='autoencoder_article_tuning'\n",
    ")\n",
    "\n",
    "\n",
    "tuner.search_space_summary()\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "tuner.search(X_train, X_train, epochs=800, batch_size=64, validation_data=(X_val, X_val), callbacks=[early_stopping])\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(\"\\nMelhores hiperpar√¢metros encontrados:\")\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "# Salva o melhor modelo em um arquivo\n",
    "best_model.save('Convencional_tunado.keras')\n",
    "print(\"\\nO melhor modelo foi salvo como 'Convencional_tunado.keras'\")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avalia√ß√£o do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Obtenha o melhor modelo do tuner\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que voc√™ j√° rodou o tuner.search()\n",
    "# e j√° tem o `best_model`\n",
    "\n",
    "# 1. Defina uma fun√ß√£o para avalia√ß√£o (opcional, mas boa pr√°tica)\n",
    "def avaliar_modelo_final(modelo, test_data):\n",
    "    psnr_total, ssim_total, ms_ssim_total, tempo_total = 0, 0, 0, 0\n",
    "    num_test_images = test_data.shape[0]\n",
    "\n",
    "    for i in range(num_test_images):\n",
    "        entrada = np.expand_dims(test_data[i], axis=0)\n",
    "        inicio = time.time()\n",
    "        saida = modelo.predict(entrada, verbose=0)\n",
    "        fim = time.time()\n",
    "        tempo_total += fim - inicio\n",
    "\n",
    "        psnr_total += tf.image.psnr(tf.image.convert_image_dtype(entrada, dtype=tf.float32),\n",
    "                                     tf.image.convert_image_dtype(saida, dtype=tf.float32),\n",
    "                                     max_val=1.0).numpy()[0]\n",
    "        ssim_total += ssim(entrada[0], saida[0], data_range=1.0, channel_axis=2)\n",
    "        ms_ssim_total += tf.image.ssim_multiscale(\n",
    "            tf.image.convert_image_dtype(entrada, dtype=tf.float32),\n",
    "            tf.image.convert_image_dtype(saida, dtype=tf.float32),\n",
    "            max_val=1.0,\n",
    "            filter_size=3\n",
    "        ).numpy()[0]\n",
    "\n",
    "    return psnr_total / num_test_images, ssim_total / num_test_images, ms_ssim_total / num_test_images, tempo_total / num_test_images\n",
    "\n",
    "# 2. Obtenha o melhor modelo do tuner\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 3. Avalie o modelo sem re-treinar\n",
    "print(\"\\nIniciando avalia√ß√£o do melhor modelo...\")\n",
    "psnr_final, ssim_final, ms_ssim_final, tempo_final = avaliar_modelo_final(best_model, X_test)\n",
    "\n",
    "print(\"\\nResultados do Autoencoder Otimizado:\")\n",
    "print(f\"  PSNR: {psnr_final:.4f}\")\n",
    "print(f\"  SSIM: {ssim_final:.4f}\")\n",
    "print(f\"  MS-SSIM: {ms_ssim_final:.4f}\")\n",
    "print(f\"  Tempo de Infer√™ncia (s): {tempo_final:.4f}\")\n",
    "\n",
    "# --- Cria√ß√£o do dicion√°rio de resultados ---\n",
    "# A chave 'Modelo Otimizado' √© o que aparecer√° no eixo X do gr√°fico\n",
    "resultados = {\n",
    "    'Modelo Otimizado': {\n",
    "        'PSNR': psnr_final,\n",
    "        'SSIM': ssim_final,\n",
    "        'MS-SSIM': ms_ssim_final,\n",
    "        'Tempo (s)': tempo_final\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melhorias Futuras\n",
    "- Uso de Keras Quartenion\n",
    "- Fun√ß√£o de perda combinada (SSIM + MSE)\n",
    "- Autoencoder assim√©trico UFRJ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7308535,
     "sourceId": 11646697,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (tf220)",
   "language": "python",
   "name": "tf220"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
